<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git</id>
    <title>风袖</title>
    <updated>2020-02-06T17:03:15.037Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://e.coding.net/zu3zz/zu3zz.coding.me.git"/>
    <link rel="self" href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/atom.xml"/>
    <subtitle>烟蛾敛略不胜态，风袖低昂如有情</subtitle>
    <logo>https://e.coding.net/zu3zz/zu3zz.coding.me.git/images/avatar.png</logo>
    <icon>https://e.coding.net/zu3zz/zu3zz.coding.me.git/favicon.ico</icon>
    <rights>All rights reserved 2020, 风袖</rights>
    <entry>
        <title type="html"><![CDATA[计算机网络面试考点总结]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/interview-network</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/interview-network">
        </link>
        <updated>2020-02-06T17:00:31.000Z</updated>
        <content type="html"><![CDATA[<h1 id="计算机网络面试考点总结">计算机网络面试考点总结</h1>
<h2 id="1-tcp的三次握手">1. TCP的三次握手</h2>
<ol>
<li>第一次握手，建立连接时，客户端发送一个SYN包，SYN=j到服务器，并且进入SYN_SEND状态，等到服务器确认</li>
<li>服务器收到SYN包，必须确认客户的SYN值（ack=j+1），同时自己也发送一个SYN包，SYN=K，级SYN + ACK包，此时服务器也进入SYN_SEND状态</li>
<li>客户端收到服务器端的SYN+ACK包，向服务器发送确认包ACK（ack = k + 1），此包发送完毕之后，客户端和服务器都进入ESTABLISHED状态，三次握手完成。</li>
</ol>
<p>####1.1 为什么需要三次握手</p>
<ul>
<li>为了初始化Seqence Number的初始值，用于拼接数据</li>
</ul>
<h4 id="12-syn超时">1.2 SYN超时</h4>
<ul>
<li>不断重试，Linux默认63秒</li>
</ul>
<h4 id="13-针对syn-flood">1.3 针对Syn Flood</h4>
<ul>
<li>
<p>syn队列满了之后，通过tcp_syncookies参数回发 SYN Cookie</p>
</li>
<li>
<p>若正常连接则Clinet会回发SYN Cookie，直接建立连接</p>
</li>
</ul>
<h4 id="14-client出现故障">1.4 Client出现故障</h4>
<ul>
<li>向对方发送保活探测报文</li>
</ul>
<h2 id="2-tcp四次挥手">2. TCP四次挥手</h2>
<ol>
<li>Client发送一个FIN，用来关系Client到Server的数据传送，Client进入FIN_WAIT_1状态</li>
<li>Server收到FIN之后，发送一个ACK给Client，确认需要为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态</li>
<li>Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态</li>
<li>Client收到FIN之后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。</li>
</ol>
<h2 id="3-tcp和udp">3. TCP和UDP</h2>
<ol>
<li>面向非连接，没有快重传等。</li>
<li>不维护连接状态，支持同时向多个客户端传输相同的消息</li>
<li>数据包报头只有8个字节</li>
<li>面向报文</li>
<li>尽最大努力交付</li>
</ol>
<hr>
<h3 id="31-区别">3.1 区别</h3>
<ol>
<li>面向连接 vs 无连接</li>
<li>可靠性</li>
<li>有序性</li>
<li>速度</li>
<li>量级</li>
</ol>
<hr>
<h3 id="32-滑动窗口协议">3.2 滑动窗口协议</h3>
<ol>
<li>RTT: 发送数据包到收到对应的ACK，所花费的时间</li>
<li>RTO: 重传时间间隔</li>
<li>使用滑动窗口做流量控制与乱序重拍
<ul>
<li>保证TCP的可靠性</li>
<li>保证TCP的流量控制特性</li>
</ul>
</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post-images/1581008533854.png" alt="" loading="lazy"></figure>
<h2 id="4-http11">4. HTTP(1.1)</h2>
<h3 id="1-主要特点">1. 主要特点</h3>
<ol>
<li>支持客户/服务器模式</li>
<li>简单快速</li>
<li>灵活</li>
<li>无连接</li>
</ol>
<hr>
<h3 id="2-请求相应的步骤">2. 请求/相应的步骤</h3>
<ol>
<li>客户端连接到Web服务器</li>
<li>发送HTTP请求</li>
<li>服务器接收请求并返回HTTP相应</li>
<li>释放连接TCP连接</li>
<li>客户端浏览器解析HTML内容</li>
</ol>
<hr>
<h3 id="3-输入url之后按下回车之后经过的流程">3. 输入URL之后，按下回车之后经过的流程</h3>
<ol>
<li>DNS解析 找对对应的IP地址</li>
<li>TCP连接</li>
<li>发送HTTP请求</li>
<li>服务器处理请求并返回HTTP报文</li>
<li>服务器解析渲染页面</li>
<li>连接结束</li>
</ol>
<hr>
<h3 id="4-http状态码">4. HTTP状态码</h3>
<ul>
<li>五种可能取值
<ul>
<li>1xx：指示信息--表示请求已接收，继续处理</li>
<li>2xx：成功--表示请求已被成功接收、理解、</li>
<li>3xx：重定向--要完成请求必须进行更进一步的操作</li>
<li>4xx：客户端错误--请求有语法错误或者请求无法实现</li>
<li>5xx：服务器端错误--服务器未能实现合法的请求</li>
</ul>
</li>
<li>常见状态码
<ul>
<li>200 OK：正常 返回信息</li>
<li>400 Bad Request：客户端请求有语法错误，不能被服务器所理解</li>
<li>401 Unauthorized：请求未经授权，这个状态码必须和WWW-Authenticate报头域一起使用</li>
<li>403 Forbidden：服务器收到请求，但是拒绝提供服务</li>
<li>404 Not Found：请求资源不存在，eg，输入了错误的URL</li>
<li>500 Internal Server Error：服务器发生不可预期的错误</li>
<li>503 Server Unabailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-get和post请求的区别">5. GET和POST请求的区别</h3>
<h4 id="1-从三个层面来解答">1. 从三个层面来解答</h4>
<ol>
<li>Http报文层面：GET将请求信息（键值对）放到URL中，POST则放在报文体中</li>
<li>数据库层面：GET符合幂等性和安全性，POST不符合（两个都不符合）</li>
<li>其他层面：GET可以被缓存、被存储，而POST不行</li>
</ol>
<hr>
<h3 id="6-cookie和session的区别">6. Cookie和Session的区别</h3>
<h4 id="cookie简介">Cookie简介</h4>
<ul>
<li>是由服务器发给客户端的特殊信息，以文本的形式存放在客户端</li>
<li>客户端再次请求的时候，会吧Cookie回发</li>
<li>服务器接收到后，会解析Cookie生成与客户端相对应的内容</li>
</ul>
<h4 id="cookie的设置以及发送过程">Cookie的设置以及发送过程</h4>
<figure data-type="image" tabindex="2"><img src="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post-images/1581008546981.png" alt="" loading="lazy"></figure>
<h4 id="session简介">Session简介</h4>
<ul>
<li>服务器端的机制，在服务器上保存的信息（类似hash表）</li>
<li>解析客户端请求并操作session id，按需保存状态信息</li>
</ul>
<h4 id="session的实现方式">Session的实现方式</h4>
<ol>
<li>使用Cookie来实现：服务器给客户端一个JSessionID</li>
<li>使用URL回写来实现</li>
</ol>
<h4 id="cookie和session的区别">Cookie和Session的区别</h4>
<ol>
<li>Cookie数据存放在客户的浏览器上，Session数据放在服务器上</li>
<li>Session相对于Cookie更安全</li>
<li>若考虑减轻服务器负担，应当使用Cookie</li>
</ol>
<h2 id="5-http和https的区别">5 HTTP和HTTPS的区别</h2>
<h3 id="1-https简介">1. HTTPS简介</h3>
<figure data-type="image" tabindex="3"><img src="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post-images/1581008556887.png" alt="" loading="lazy"></figure>
<hr>
<h3 id="2-sslsecurity-sockets-layer-安全套接层">2. SSL（Security Sockets Layer, 安全套接层）</h3>
<ol>
<li>为网络通信提供安全以及数据完整性的一种安全协议</li>
<li>是操作系统对外的API，SSL3.0后更名为TLS</li>
<li>采用身份验证和数据加密保证网络通信的安全和数据的完整性</li>
</ol>
<hr>
<h3 id="3-加密方式">3. 加密方式</h3>
<ol>
<li>对称加密：加密和解密都使用同一个密钥</li>
<li>非对称加密：加密使用的密钥和解密使用的密钥是不相同的</li>
<li>哈希算法：将任意长度的信息转换为固定长度的值，算法不可逆</li>
<li>数字签名：证明某个信息或者文件是某个人发出/认同的</li>
</ol>
<hr>
<h3 id="4-数据传输流程">4. 数据传输流程</h3>
<ol>
<li>浏览器将支持的加密算法信息发送给服务器</li>
<li>服务器选择一套浏览器支持的加密算法，以证书的形式回发浏览器</li>
<li>浏览器验证证书合法性，并结合证书公钥加密信息发送给服务器</li>
<li>服务器使用私钥解密信息，验证哈希，加密响应消息回发浏览器</li>
<li>浏览器解密响应信息，并对消息进行验证，之后就用同一套秘钥进行加密交换</li>
</ol>
<hr>
<h3 id="5-http和https的区别-2">5. HTTP和HTTPS的区别</h3>
<ol>
<li>HTTPS需要到CA申请证书，HTTP不需要</li>
<li>HTTPS密文传输，HTTP明文传输</li>
<li>连接方式不同，HTTPS默认使用443端口，HTTP使用80端口</li>
<li>HTTPS = HTTP+加密+认证+完整性保护，较HTTP安全</li>
</ol>
<hr>
<h3 id="6-潜在危险">6. 潜在危险</h3>
<ol>
<li>浏览器默认填充http：// ，请求需要进行跳转，又被劫持的风险</li>
<li>可以使用HSTS（HTTP Strict Transport Security）优化</li>
</ol>
<h2 id="6-socket">6. Socket</h2>
<ul>
<li>Socket是对TCP/IP协议的抽象，是操作系统对外开放的接口</li>
</ul>
<h3 id="1-socket通信流程">1. Socket通信流程</h3>
<figure data-type="image" tabindex="4"><img src="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post-images/1581008567663.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SparkSQL实战笔记（2）---- SparkSQL 概述]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/sparksql-2</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/sparksql-2">
        </link>
        <updated>2020-01-14T11:46:21.000Z</updated>
        <content type="html"><![CDATA[<h1 id="sparksql-实战笔记2-sparksql-概述">SparkSQL 实战笔记（2）---- SparkSQL 概述</h1>
<p>##1. 为什么需要 SQL？</p>
<ol>
<li>
<p>事实上的标准</p>
<ul>
<li>
<p>MySQL/Oracle/DB2... RBDMS 关系型数据库 是不是过时呢？</p>
</li>
<li>
<p>数据规模 大数据的处理</p>
<pre><code class="language-shell">MR：Java
Spark：Scala、Java、Python
</code></pre>
</li>
<li>
<p>直接使用 SQL 语句来对数据进行处理分析呢？ 符合市场的需求</p>
<pre><code class="language-shell">Hive SparkSQL Impala...
</code></pre>
</li>
<li>
<p>受众面大、容易上手、易学易用:<code>DDL DML</code></p>
<pre><code class="language-shell"># access.log日志
1,zhangsan,10,beijing
2,lisi,11,shanghai
3,wangwu,12,shenzhen
</code></pre>
</li>
<li>
<p><code>table: Hive/Spark SQL/Impala</code> ：共享元数据</p>
<ul>
<li>name: access</li>
<li>columns: id int,name string,age int,city string</li>
</ul>
<pre><code class="language-mysql">SQL: select xxx from access where ... group by ... having....
</code></pre>
</li>
</ul>
</li>
</ol>
<h2 id="2-sql-on-hadoop">2. SQL on Hadoop</h2>
<ol>
<li>
<p>使用 SQL 语句对大数据进行统计分析，数据是在 Hadoop</p>
</li>
<li>
<p><code>Apache Hive</code></p>
<ul>
<li>SQL 转换成一系列可以在 Hadoop 上运行的 MapReduce/Tez/Spark 作业</li>
<li>SQL 到底底层是运行在哪种分布式引擎之上的，是可以通过一个参数来设置</li>
<li>功能：
<ul>
<li>SQL：命令行、代码</li>
<li>多语言 Apache Thrift 驱动</li>
<li>自定义的 UDF 函数：按照标准接口实现，打包，加载到 Hive 中</li>
<li>元数据</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>Cloudera Impala</code></p>
<ul>
<li>使用了自己的执行守护进程集合，一般情况下这些进程是需要与 Hadoop DN 安装在一个节点上</li>
<li>功能：
<ul>
<li>92 SQL 支持</li>
<li>Hive 支持</li>
<li>命令行、代码</li>
<li>与 Hive 能够共享元数据</li>
<li>性能方面是 Hive 要快速一些，基于内存</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>Spark SQL</code></p>
<ul>
<li>
<p>Spark 中的一个子模块，是不是仅仅只用 SQL 来处理呢？</p>
<pre><code class="language-shell">$ Hive：SQL ==&gt; MapReduce
</code></pre>
</li>
<li>
<p><code>Spark</code>：能不能直接把 SQL 运行在 Spark 引擎之上呢？</p>
<ol>
<li><code>Shark</code>： <code>SQL==&gt;Spark</code> （不再维护）
<ul>
<li>优点：快 与 Hive 能够兼容</li>
<li>缺点：执行计划优化完全依赖于 Hive 进程 vs 线程</li>
<li>使用：需要独立维护一个打了补丁的 Hive 源码分支</li>
</ul>
</li>
<li><code>Spark SQL</code>: 这是 Spark 项目中的<code>SQL</code>子项目</li>
</ol>
</li>
</ul>
</li>
<li>
<p><code>Hive on Spark</code> ： 这是<code>Hive</code>项目中的，通过切换 Hive 的执行引擎即可，底层添加了 Spark 执行引擎的支持</p>
</li>
<li>
<p><code>Presto</code></p>
<ul>
<li>交互式查询引擎 SQL</li>
<li>功能：
<ul>
<li>共享元数据信息</li>
<li>92 SQL 语法</li>
<li>提供了一系列的连接器，<code>Hive</code> <code>Cassandra</code>...</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>Drill</code></p>
<ol>
<li>HDFS、Hive、Spark SQL</li>
<li>支持多种后端存储，然后直接进行各种后端数据的处理</li>
<li>未来的趋势</li>
</ol>
</li>
<li>
<p><code>Phoenix</code></p>
<ol>
<li>HBase 的数据，是要基于 API 进行查询</li>
<li>Phoenix 使用 SQL 来查询 HBase 中的数据</li>
<li>主要点：如果想查询的快的话，还是取决于 ROWKEY 的设计</li>
</ol>
</li>
</ol>
<h2 id="3-spark-sql-是什么">3. Spark SQL 是什么</h2>
<h3 id="31-spark-sql-概念">3.1 Spark SQL 概念</h3>
<ol>
<li>
<p>Spark SQL is Apache Spark's module for working with structured data.</p>
<ul>
<li>误区一：Spark SQL 就是一个 SQL 处理框架</li>
</ul>
<ol>
<li>
<p>集成性：在 Spark 编程中无缝对接多种复杂的 SQL</p>
</li>
<li>
<p>统一的数据访问方式：以类似的方式访问多种不同的数据源，而且可以进行相关操作</p>
<pre><code class="language-scala">spark.read.format(&quot;json&quot;).load(path)
spark.read.format(&quot;text&quot;).load(path)
spark.read.format(&quot;parquet&quot;).load(path)
spark.read.format(&quot;json&quot;).option(&quot;...&quot;,&quot;...&quot;).load(path)
</code></pre>
</li>
<li>
<p>兼容 Hive</p>
<ul>
<li>allowing you to access existing Hive warehouses</li>
<li>如果你想把 Hive 的作业迁移到 Spark SQL，这样的话，迁移成本就会低很多</li>
</ul>
</li>
<li>
<p>标准的数据连接：提供标准的<code>JDBC/ODBC</code>连接方式到 Server 上</p>
</li>
</ol>
</li>
<li>
<p>Spark SQL 应用并不局限于 SQL</p>
<ol>
<li>还支持 Hive、JSON、Parquet 文件的直接读取以及操作</li>
<li>SQL 仅仅是 Spark SQL 中的一个功能而已</li>
</ol>
</li>
<li>
<p>为什么要学习 Spark SQL</p>
<ol>
<li>SQL 带来的便利性</li>
<li>Spark Core： RDD Scala/Java
<ul>
<li>需要熟悉 Java、Scala 语言</li>
</ul>
</li>
<li>Spark SQL
<ul>
<li>Catalyst 为我们自动做了很多的优化工作</li>
<li>SQL(只要了解业务逻辑，然后使用 SQL 来实现)</li>
<li>DF/DS：面向 API 编程的，使用一些 Java/Scala</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="32-spark-sql-架构">3.2 Spark SQL 架构</h3>
<h4 id="321-前端frontend">3.2.1 前端（FrontEnd）</h4>
<ol>
<li>
<p>Hive AST : SQL 语句（字符串）==&gt; 抽象语法树</p>
</li>
<li>
<p>Spark Program : DF/DS API</p>
</li>
<li>
<p>Streaming SQL</p>
</li>
<li>
<p>Catalyst</p>
<ul>
<li>Unresolved LogicPlan</li>
</ul>
<pre><code class="language-mysql">select empno, ename from emp
</code></pre>
</li>
<li>
<p>Schema Catalog 和 MetaStore</p>
</li>
<li>
<p>LogicPlan</p>
</li>
<li>
<p>Optimized LogicPlan</p>
<pre><code class="language-mysql">select * from (select ... from xxx limit 10) limit 5;
将我们的SQL作用上很多内置的Rule，使得我们拿到的逻辑执行计划是比较好的
</code></pre>
<p><code>Physical Plan</code></p>
</li>
</ol>
<h4 id="322-后端backend">3.2.2 后端（Backend）</h4>
<ol>
<li>
<p><code>spark-shell</code></p>
<ul>
<li>每个 Spark 应用程序（spark-shell）在不同目录下启动，其实在该目录下是有 metastore_db</li>
<li>单独的</li>
<li>如果你想 spark-shell 共享我们的元数据的话，肯定要指定元数据信息==&gt; 后续讲 Spark SQL 整合 Hive 的时候讲解</li>
<li><code>spark.sql</code>(sql 语句)</li>
</ul>
</li>
<li>
<p>spark-sql 的使用<br>
spark-shell 你会发现如果要操作 SQL 相关的东西，要使用 spark.sql(sql 语句)</p>
<pre><code class="language-mysql">explain extended
select a.key\*(3+5), b.value from t a join t b on a.key = b.key and a.key &gt; 3;
</code></pre>
<ul>
<li>优化的过程中，可以把一些条件过滤前置</li>
</ul>
</li>
<li>
<p>spark-shell 启动流程分析</p>
<ul>
<li>
<p>REPL: Read-Eval-Print Loop 读取-求值-输出</p>
</li>
<li>
<p>提供给用户即时交互一个命令窗口</p>
<pre><code class="language-mysql">case \$变量名 in
模式 1
command1
;;
模式 2
command2
;;
\*)
default
;;
esac
</code></pre>
</li>
<li>
<p>spark-shell 底层调用的是 spark-submit</p>
</li>
<li>
<p>spark-submit 底层调用的是 spark-class</p>
</li>
</ul>
</li>
<li>
<p><strong>spark-sql 执行流程分析</strong></p>
<ul>
<li>spark-sql 底层调用的也是 spark-submit</li>
<li>因为 spark-sql 它就是一个 Spark 应用程序，和 spark-shell 一样</li>
<li>对于你想启动一个 Spark 应用程序，肯定要借助于 spark-submit 这脚本进行提交</li>
<li>spark-sql 调用的类是<code>org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver</code></li>
<li>spark-shell 调用的类是 <code>org.apache.spark.repl.Main</code></li>
</ul>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SparkSQL实战笔记（1）---- 部署、项目准备]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/sparksql-1</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/sparksql-1">
        </link>
        <updated>2020-01-13T08:43:13.000Z</updated>
        <content type="html"><![CDATA[<h1 id="sparksql实战笔记1-部署-项目准备">SparkSQL实战笔记（1）---- 部署、项目准备</h1>
<h2 id="1-关于mapreduce的问题">1. 关于MapReduce的问题</h2>
<ul>
<li>
<p>MapReduce的槽点一</p>
<ul>
<li>
<p>需求：统计单词出现的个数（词频统计）</p>
<ul>
<li>
<p>file中每个单词出现的次数</p>
<pre><code class="language-txt">hello,hello,hello
world,world
pk
</code></pre>
</li>
</ul>
</li>
</ul>
<ol>
<li>读取file中每一行的数据</li>
<li>按照分隔符把每一行的内容进行拆分</li>
<li>按照相同的key分发到同一个任务上去进行累加的操作</li>
</ol>
<ul>
<li>
<p>这是一个简单的不能再简单的一个需求，我们需要开发很多的代码</p>
<ol>
<li>自定义Mapper</li>
<li>自定义Reducer</li>
<li>通过Driver把Mapper和Reducer串起来</li>
<li>打包，上传到集群上去</li>
<li>在集群上提交我们的wc程序</li>
</ol>
</li>
<li>
<p>一句话：就是会花费非常多的时间在非业务逻辑改动的工作上</p>
</li>
</ul>
</li>
<li>
<p>MapReduce吐槽点二</p>
<pre><code class="language-shell">Input =&gt; MapReduce ==&gt; Output ==&gt; MapReduce ==&gt; Output
</code></pre>
</li>
<li>
<p>回顾下MapReduce执行流程：</p>
<ul>
<li>MapTask或者ReduceTask都是进程级别</li>
<li>第一个MR的输出要先落地，然后第二个MR把第一个MR的输出当做输入</li>
<li>中间过程的数据是要落地</li>
</ul>
</li>
</ul>
<h2 id="2-spark">2. Spark</h2>
<ol>
<li>
<p>特性</p>
<ol>
<li>
<p>Speed:</p>
<ul>
<li>
<p>both batch and streaming data</p>
</li>
<li>
<p>批流一体 Spark Flink</p>
</li>
</ul>
</li>
<li>
<p>Ease of Use</p>
<ul>
<li>high-level operators</li>
</ul>
</li>
<li>
<p>Generality</p>
<ul>
<li>stack  栈   生态</li>
</ul>
</li>
<li>
<p>Runs Everywhere</p>
<ul>
<li>It can access diverse data sources</li>
<li>YARN/Local/Standalone Spark应用程序的代码需要改动吗？</li>
<li>--master来指定你的Spark应用程序将要运行在什么模式下</li>
</ul>
</li>
</ol>
</li>
</ol>
<h2 id="3-部署问题">3. 部署问题</h2>
<h3 id="31-jdk部署">3.1 <code>JDK</code>部署</h3>
<ul>
<li>
<p>下载：https://www.oracle.com/index.html</p>
</li>
<li>
<p>服务器端：</p>
<ul>
<li>
<p>下载linux版本的jdk</p>
</li>
<li>
<p>解压：<code>tar -zxvf jdk-8u91-linux-x64.tar.gz -C ~/app</code></p>
</li>
<li>
<p>配置环境变量： <code>~/.bash_profile</code></p>
<pre><code class="language-shell">export JAVA_HOME=/home/hadoop/app/jdk1.8.0_91
export PATH=$JAVA_HOME/bin:$PATH
</code></pre>
</li>
<li>
<p>使环境变量生效：<code>source ~/.bash_profile</code></p>
</li>
</ul>
</li>
<li>
<p>客户端：Win/Mac/Linux</p>
<ul>
<li>Mac/Linux：就和服务器端安装方法一致</li>
</ul>
</li>
</ul>
<h3 id="32-maven和idea部署">3.2 <code>Maven</code>和<code>IDEA</code>部署</h3>
<ol>
<li>
<p>Maven：IDEA+Maven来管理应用程序</p>
<ul>
<li>为什么你开发的时候不直接拷贝jar包呢？</li>
<li>在maven中的pom.xml中添加我们所需要的dependency就行</li>
</ul>
</li>
<li>
<p>官网：maven.apache.org</p>
<ul>
<li>
<p><code>wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz</code></p>
</li>
<li>
<p>解压：<code>tar -zxvf apache-maven-3.6.1-bin.tar.gz -C ~/app/</code></p>
</li>
<li>
<p>配置环境变量：<code>~/.bash_profile</code></p>
<pre><code class="language-shell">export MAVEN_HOME=/home/hadoop/app/apache-maven-3.6.1
export PATH=$MAVEN_HOME/bin:$PATH
</code></pre>
</li>
<li>
<p>使环境变量生效：<code>source ~/.bash_profile</code></p>
</li>
<li>
<p>服务器端：你是需要进行使用maven来编译我们的spark</p>
</li>
<li>
<p>客户端：Win/Mac/Linux</p>
</li>
<li>
<p>我们开发应用程序是在本地/本机，IDEA+Maven，所以本地也是需要安装maven的</p>
</li>
<li>
<p>本地Win/Mac/Linux的maven安装方式和服务器端是一模一样的</p>
</li>
<li>
<p>如果你是win用户，一定要注意: $MAVEN_HOME/conf/setting.xml</p>
<pre><code class="language-xml">&lt;!-- localRepository
	   | The path to the local repository maven will use to store artifacts.
	   |
	   | Default: ${user.home}/.m2/repository
	  &lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;
	  --&gt;
</code></pre>
</li>
<li>
<p>Win用户，默认是在C盘，所以建议大家更改Maven本地仓库的路径</p>
</li>
</ul>
</li>
<li>
<p>IDEA官网：http://www.jetbrains.com/</p>
</li>
</ol>
<h3 id="33-hadoop部署">3.3 <code>Hadoop</code>部署</h3>
<h4 id="331-使用cdh-cdh5151">3.3.1 使用<code>CDH</code> <code>cdh5.15.1</code></h4>
<ul>
<li>
<p>下载地址：https://archive.cloudera.com/cdh5/cdh/5/</p>
</li>
<li>
<p>Hadoop：<code>wget https://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.15.1.tar.gz</code></p>
</li>
<li>
<p>解压：<code>tar -zxvf hadoop-2.6.0-cdh5.15.1.tar.gz -C ~/app/</code></p>
</li>
<li>
<p>修改<code>hadoop-env.sh</code></p>
<pre><code class="language-shell">export JAVA_HOME=/home/hadoop/app/jdk1.8.0_91
</code></pre>
</li>
<li>
<p>修改core-site.xml</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;fs.default.name&lt;/name&gt;
	&lt;value&gt;hdfs://hadoop000:8020&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>修改hdfs-site.xml</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;/home/hadoop/tmp/dfs/data&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
	&lt;name&gt;dfs.permissions&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>修改yarn-site.xml</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
	&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>修改mapred-site.xml</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
	&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>修改slaves（可选）</p>
<ul>
<li>hadoop000</li>
</ul>
</li>
<li>
<p>配置系统环境变量</p>
<pre><code class="language-shell">export HADOOP_HOME=/home/hadoop/app/hadoop-2.6.0-cdh5.15.1
export PATH=$HADOOP_HOME/bin:$PATH
</code></pre>
</li>
<li>
<p>配置SSH的免密码登录</p>
</li>
<li>
<p>在启动HDFS之前，一定要先对HDFS对格式化</p>
<ul>
<li>切记：格式化只会一次，因为一旦格式化了，那么HDFS上的数据就没了</li>
<li>格式化命令：<code>hdfs namenode -format</code></li>
</ul>
</li>
<li>
<p>启动HDFS</p>
<ol>
<li>
<p>逐个进程启动/停止</p>
<pre><code class="language-shell">$ hadoop-daemon.sh start/stop namenode
$ hadoop-daemon.sh start/stop datanode
</code></pre>
<ul>
<li>jps验证</li>
<li>如果发现有缺失的进程，那么就找缺失进程的名称对应的日志(log而不是out)</li>
</ul>
</li>
<li>
<p>一键式启动HDFS</p>
<pre><code class="language-shell">$ start-dfs.sh
$ stop-dfs.sh
</code></pre>
</li>
</ol>
</li>
</ul>
<h3 id="34-hive部署">3.4 Hive部署</h3>
<ol>
<li>
<p>Hadoop：wget https://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.15.1.tar.gz</p>
</li>
<li>
<p>系统环境变量</p>
<pre><code class="language-shell">export HIVE_HOME=/home/hadoop/app/hive-1.1.0-cdh5.15.1
export PATH=$HIVE_HOME/bin:$PATH
</code></pre>
</li>
<li>
<p>需要安装<code>MySQL</code> 与<code>yum</code></p>
<ul>
<li>
<p>需要拷贝MySQL的驱动$HIVE_HOME/lib  版本5.x</p>
</li>
<li>
<p>修改<code>$HIVE_HOME/conf/hive-site.xml</code>文件</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
  &lt;value&gt;jdbc:mysql://localhost:3306/pk?createDatabaseIfNotExist=true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;

&lt;/configuration&gt;
</code></pre>
</li>
</ul>
</li>
<li>
<p>Hive: HDFS上的数据 + MySQL中元数据信息</p>
</li>
</ol>
<h2 id="4-spark运行模式">4. Spark运行模式</h2>
<ol>
<li>local：本地运行，在开发代码的时候，我们使用该模式进行<strong>测试</strong>是非常方便的</li>
<li>standalone：Hadoop部署多个节点的，同理Spark可以部署多个节点  <strong>用的不多</strong></li>
<li>YARN：将Spark作业提交到Hadoop(YARN)集群中运行，Spark仅仅只是一个客户端而已 <strong>最多的用法</strong></li>
<li>Mesos：不常用</li>
<li>K8S：2.3版本才正式稍微稳定   是未来比较好的一个方向</li>
<li>补充：运行模式和代码没有任何关系，同一份代码可以不做修改运行在不同的运行模式下</li>
</ol>
<h2 id="5-构建应用">5. 构建应用</h2>
<ol>
<li>
<p>使用<code>IDEA</code>+<code>Maven</code>来构建我们的Spark应用</p>
</li>
<li>
<p>在命令行中运行一下<code>MAVEN</code>命令</p>
<pre><code class="language-shell">mvn archetype:generate -DarchetypeGroupId=net.alchim31.maven \
-DarchetypeArtifactId=scala-archetype-simple \
-DremoteRepositories=http://scala-tools.org/repo-releases \
-DarchetypeVersion=1.5 \
-DgroupId=com.imooc.bigdata \
-DartifactId=sparksql-train \
-Dversion=1.0
</code></pre>
</li>
<li>
<p>打开IDEA，把这个项目中的pom.xml打开即可</p>
</li>
<li>
<p>同时，在<code>pom.xml</code>中添加一下相关配置</p>
<pre><code class="language-xml">pom.xml
&lt;properties&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;encoding&gt;UTF-8&lt;/encoding&gt;
    &lt;scala.tools.version&gt;2.11&lt;/scala.tools.version&gt;
    &lt;scala.version&gt;2.11.8&lt;/scala.version&gt;
    &lt;spark.version&gt;2.4.3&lt;/spark.version&gt;
    &lt;hadoop.version&gt;2.6.0-cdh5.15.1&lt;/hadoop.version&gt;
&lt;/properties&gt;	

添加CDH的仓库
&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;cloudera&lt;/id&gt;
        &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos&lt;/url&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;

添加Spark SQL和Hadoop Client的依赖
&lt;!--Spark SQL依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- Hadoop相关依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
    &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
    &lt;version&gt;${hadoop.version}&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ol>
<h2 id="6-实战词频统计案例">6. 实战：词频统计案例</h2>
<ol>
<li>
<p>输入：文件</p>
<ul>
<li>需求：统计出文件中每个单词出现的次数
<ol>
<li>读每一行数据</li>
<li>按照分隔符把每一行的数据拆成单词</li>
<li>每个单词赋上次数为1</li>
<li>按照单词进行分发，然后统计单词出现的次数</li>
<li>把结果输出到文件中</li>
</ol>
</li>
</ul>
</li>
<li>
<p>输出：文件</p>
</li>
<li>
<p>使用local模式运行spark-shell</p>
<pre><code class="language-shell">./spark-shell --master local
</code></pre>
<ul>
<li>
<p>打包我们的应用程序，让其运行在local模式下</p>
</li>
<li>
<p>如何运行jar包呢？</p>
</li>
</ul>
<pre><code class="language-shell">./spark-submit \
--class  com.imooc.bigdata.chapter02.SparkWordCountAppV2 \
--master local \
/home/hadoop/lib/sparksql-train-1.0.jar \
file:///home/hadoop/data/wc.data file:///home/hadoop/data/out 
</code></pre>
<ul>
<li>使用local模式的话，你只需要把spark的安装包解压开，什么都不用动，就能使用</li>
</ul>
</li>
<li>
<p>如何提交Spark应用程序到YARN上执行</p>
<pre><code class="language-shell">./spark-submit \
--class  com.imooc.bigdata.chapter02.SparkWordCountAppV2 \
--master yarn \
--name SparkWordCountAppV2 \
/home/hadoop/lib/sparksql-train-1.0.jar \
hdfs://hadoop000:8020/pk/wc.data hdfs://hadoop000:8020/pk/out
</code></pre>
</li>
<li>
<p>要将Spark应用程序运行在YARN上，一定要配置<code>HADOOP_CONF_DIR</code>或者<code>YARN_CONF_DIR</code></p>
<p>指向<code>$HADOOP_HOME/etc/conf</code></p>
</li>
<li>
<p>local和YARN模式：重点掌握</p>
</li>
<li>
<p>Standalone：了解</p>
<ul>
<li>
<p>多个机器，那么你每个机器都需要部署spark</p>
</li>
<li>
<p>相关配置：</p>
<pre><code class="language-shell">$SPARK_HOME/conf/slaves
	hadoop000
SPARK_HOME/conf/spark-env.sh
	SPARK_MASTER_HOST=hadoop000
</code></pre>
</li>
<li>
<p>启动Spark集群</p>
<pre><code class="language-shell">$SPARK_HOME/sbin/start-all.sh
jps： Master  Worker
</code></pre>
</li>
<li>
<p>spark提交作业</p>
<pre><code class="language-shell">./spark-submit \
--class  com.imooc.bigdata.chapter02.SparkWordCountAppV2 \
--master spark://hadoop000:7077 \
--name SparkWordCountAppV2 \
/home/hadoop/lib/sparksql-train-1.0.jar \
hdfs://hadoop000:8020/pk/wc.data hdfs://hadoop000:8020/pk/out2
</code></pre>
</li>
<li>
<p>不管什么运行模式，代码不用改变，只需要在<code>spark-submit</code>脚本提交时</p>
<p>通过<code>--master xxx</code> 来设置你的运行模式即可</p>
</li>
</ul>
</li>
</ol>
<h2 id="7-实战代码">7. 实战代码</h2>
<ul>
<li><code>Scala</code>版本</li>
</ul>
<pre><code class="language-scala">package com.zth.bigdata.examples
import org.apache.spark.{SparkConf, SparkContext}
/**
 * Author: 3zZ.
 * Date: 2020/1/13 3:14 下午
 */
object SparkWordCountApp {
  def main(args: Array[String]): Unit = {
    /**
     * master: 运行模式 local
     */
    val sparkConf = new SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;SparkWordCountApp&quot;)
    val sc = new SparkContext(sparkConf)

    val rdd = sc.textFile(&quot;/Users/3zz/Code/Spark/spark-sql-train/data/input.txt&quot;)
    /**
     * 按照单词个数进行降序排列
     */
    rdd.flatMap(_.split(&quot;,&quot;)).map((_, 1))
      .reduceByKey(_ + _).map(x =&gt; (x._2, x._1))
      .sortByKey(false).map(x =&gt;(x._2,x._1))
      .collect().foreach(println)
    //      .saveAsTextFile(&quot;/Users/3zz/Code/Spark/spark-sql-train/data/out&quot;).
    sc.stop()
  }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HBase学习笔记 ---- 整合篇]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/hbase-1</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/hbase-1">
        </link>
        <updated>2020-01-11T15:54:39.000Z</updated>
        <content type="html"><![CDATA[<h1 id="hbase">Hbase</h1>
<h2 id="1-数据存储">1. 数据存储</h2>
<h3 id="11-rdbms">1.1 RDBMS:</h3>
<ol>
<li>
<p>Data is typed structured before stored</p>
</li>
<li>
<p>传统SQL</p>
<table>
<thead>
<tr>
<th>data</th>
<th>location</th>
</tr>
</thead>
<tbody>
<tr>
<td>entity</td>
<td>table</td>
</tr>
<tr>
<td>record</td>
<td>row</td>
</tr>
<tr>
<td>query</td>
<td>group by 、join</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>大数据时代，如何做实时查询？</p>
</li>
<li>
<p>hadoop/HDFS：能存 没法进行实时查询，随机读写</p>
</li>
<li>
<p>NoSQL（NOT only SQL）：HBase、Redis</p>
</li>
</ol>
<h3 id="12-hbase在hadoop生态圈中的位置">1.2 Hbase在Hadoop生态圈中的位置</h3>
<ol>
<li>HBase是Hadoop生态圈中的一个重要组成部分</li>
<li>HBase是构建在HDFS纸上，也就是说HBase的数据可以存储在HDFS上面</li>
<li>可以通过MapReduce/Spark来处理Hbase中的数据</li>
<li>HBase也提供了shell、API的方式进行数据的访问</li>
</ol>
<h3 id="13-行式vs列式">1.3 行式VS列式</h3>
<ol>
<li>
<p>行式</p>
<ul>
<li>
<p>按行存储</p>
</li>
<li>
<p>没有索引查询的时候需要耗费大量的IO</p>
</li>
<li>
<p>可以通过建立索引或者视图来提速</p>
</li>
<li>
<p>1,3zz,23</p>
</li>
</ul>
</li>
<li>
<p>列式</p>
<ul>
<li>压缩、并行处理</li>
<li>数据就是索引，大大降低IO</li>
</ul>
</li>
</ol>
<h3 id="14-hbase特点">1.4 HBase特点</h3>
<ol>
<li>
<p>大：数据量大</p>
</li>
<li>
<p>面向列：列族（可以存放很多列），列族/列独立索引</p>
</li>
<li>
<p>稀疏：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>age</th>
<th>...</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>3zz</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>4xx</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>5yy</td>
<td>0</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>数据类型单一：byte/string</p>
</li>
<li>
<p>无模式：每一行的数据所对应的列不一定相同，每行的列是可以动态添加的</p>
<pre><code class="language-shell">3zz age/birthday/company
4xx company/province/city
</code></pre>
</li>
<li>
<p>数据多版本：比如company可以存放不同的版本的值</p>
<p>默认情况下版本号是自动分配的，是列的值插入时的时间戳</p>
</li>
</ol>
<h3 id="15-hbase-vs-mysql">1.5 HBase VS MySQL</h3>
<ol>
<li>
<p>数据类型不同</p>
</li>
<li>
<p>数据操作：</p>
<ol>
<li>关联查询：MapReduce/Spark/Phoenix</li>
<li>get/put/scan...</li>
</ol>
</li>
<li>
<p>存储模式</p>
<ol>
<li>
<p>MySQL</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>age</th>
<th>tel</th>
<th>Address</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>a</td>
<td>11</td>
<td>123</td>
<td>...</td>
</tr>
<tr>
<td>2</td>
<td>b</td>
<td>22</td>
<td>456</td>
<td>...</td>
</tr>
<tr>
<td>3</td>
<td>c</td>
<td>33</td>
<td>789</td>
<td>...</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>在HBase中</p>
<pre><code class="language-shell">basic_info: id	name 
private_info: age	tel		address
</code></pre>
</li>
</ol>
</li>
<li>
<p>transaction事务性：单行</p>
</li>
<li>
<p>数据量：HBase大</p>
</li>
<li>
<p>吞吐量：Million级别</p>
</li>
</ol>
<h3 id="hbase-vs-hdfs">HBase vs HDFS</h3>
<ol>
<li>write pattern（写模式）</li>
<li>read pattern（读模式）</li>
<li>SQL</li>
<li>data size（数据量）</li>
</ol>
<h3 id="hbase优势">HBase优势</h3>
<ol>
<li>成熟</li>
<li>高效</li>
<li>分布式</li>
</ol>
<h3 id="数据模型">数据模型</h3>
<ol>
<li>
<p>rowkey</p>
<ul>
<li>
<p>主键</p>
</li>
<li>
<p>字符串，按字典顺序存储，在HBase内部保存的是字节数组</p>
</li>
</ul>
</li>
<li>
<p>列族：Column Family （CF）</p>
<ul>
<li>
<p>是在创建表的时候就要指定的</p>
</li>
<li>
<p>列族是一系列列的集合</p>
</li>
<li>
<p>一个列族所有列有着相同的前缀</p>
<pre><code class="language-shell">basic_info: id
basic_info: name
private_info: age
private_info: tel
private_info: address
</code></pre>
</li>
</ul>
</li>
<li>
<p>列：Column / Qualifier</p>
<ul>
<li>属于某一个列族</li>
</ul>
</li>
<li>
<p>每条记录被划分到若干个CF中，每条记录对应一个rowkey，每个CF由一个或者多个Column构成</p>
</li>
<li>
<p>存储单元：Cell</p>
<ul>
<li>HBase中ROW和Column确定的一个存储单元</li>
<li>每个Cell都保存这同一份数据的多个版本</li>
<li>在写入数据时，时间戳可以由HBase自动赋值，也可以显示赋值</li>
<li>每个Cell中，不同版本的数据按照时间戳的倒序排列</li>
</ul>
<pre><code class="language-shell">{rowkey, column, version} ==&gt; HBase 中的一个Cell
</code></pre>
</li>
</ol>
<h2 id="2-hbase安装">2. HBase安装</h2>
<h3 id="21-前置需要">2.1 前置需要</h3>
<ol>
<li>JDK（略过）</li>
<li>ZooKeeper安装（brew）</li>
<li>Hadoop安装（使用cdh版本，详细配置参照前面博客）</li>
</ol>
<h3 id="22hbase安装">2.2HBase安装：</h3>
<ol>
<li>
<p>在.bash_profile中添加HBASE_HOME</p>
</li>
<li>
<p>在HBase的<code>conf</code>目录中修改两个文件</p>
<ol>
<li>
<p>在<code>hbase-env.sh</code>文件中</p>
<pre><code class="language-shell"># 1.修改java的路径
# The java implementation to use.  Java 1.7+ required.
# export JAVA_HOME=/usr/java/jdk1.6.0/
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-12.0.1.jdk/Contents/Home
# 注意 这里一定要是用1.8的版本！ 上面使用java12是要出大问题的


# 2.修改zookeeper配置
# Tell HBase whether it should manage it's own instance of Zookeeper or not.
export HBASE_MANAGES_ZK=false
</code></pre>
</li>
<li>
<p>在<code>hbase-site.xml</code>中配置</p>
<pre><code class="language-xml">&lt;configuration&gt;
&lt;!--hbase的数据存放地址（本机）--&gt;
&lt;property&gt;
  &lt;name&gt;hbase.rootdir&lt;/name&gt;
  &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;
&lt;/property&gt;
&lt;!--分布式配置--&gt;
&lt;property&gt;
  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;!--本机zookeeper地址--&gt;
&lt;property&gt;
  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
  &lt;value&gt;localhost:2181&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ol>
</li>
</ol>
<h3 id="23-启动hbase">2.3 启动HBase</h3>
<ol>
<li>先启动hadoop目录下<code>sbin/start-dfs.sh</code></li>
<li>启动zookeeper<code>zKserver start</code></li>
<li>启动HBase目录下的<code>bin/start-hbase.sh</code></li>
<li>打开本机60010端口，有界面 则成功</li>
</ol>
<h3 id="24-hbase-shell使用">2.4 HBase shell使用</h3>
<ol>
<li>在<code>bin</code>目录下输入<code>hbase shell</code>即可进入shell脚本
<ol>
<li>查看版本<code>version</code></li>
<li>查看服务器的状态<code>status</code></li>
</ol>
</li>
</ol>
<h2 id="3-hbase相关操作">3. HBase相关操作</h2>
<h3 id="31-ddl操作">3.1 DDL操作</h3>
<ul>
<li>创建、查询</li>
</ul>
<pre><code class="language-sql"># 创建
create 'member','member_id','address','info'
# 查询详细信息
desc 'member'
</code></pre>
<ul>
<li>返回信息如下：</li>
</ul>
<pre><code class="language-shell">{NAME =&gt; 'address', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCOD
ING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICA
TION_SCOPE =&gt; '0'}                                                                                                              
{NAME =&gt; 'info', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING
 =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICATIO
N_SCOPE =&gt; '0'}                                                                                                                 
{NAME =&gt; 'member_id', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENC
ODING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLI
CATION_SCOPE =&gt; '0'} 
</code></pre>
<ul>
<li>也可以在图形化界面，即60010端口上查看,点击最上面的<code>Table Details</code></li>
</ul>
<pre><code class="language-shell"># 查看有哪些表
hbase(main):007:0&gt; list
=&gt; [&quot;member&quot;]
# 删除列族中的一列
hbase(main):008:0&gt; alter 'member' ,'delete'=&gt;'member_id'
1/1 regions updated.
Done.
</code></pre>
<ul>
<li>此时在查看<code>member</code>表的结构</li>
</ul>
<pre><code class="language-shell">hbase(main):009:0&gt; desc 'member'

COLUMN FAMILIES DESCRIPTION                                                                                                     
{NAME =&gt; 'address', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCOD
ING =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICA
TION_SCOPE =&gt; '0'}                                                                                                              
{NAME =&gt; 'info', BLOOMFILTER =&gt; 'ROW', VERSIONS =&gt; '1', IN_MEMORY =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', DATA_BLOCK_ENCODING
 =&gt; 'NONE', TTL =&gt; 'FOREVER', COMPRESSION =&gt; 'NONE', MIN_VERSIONS =&gt; '0', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536', REPLICATIO
N_SCOPE =&gt; '0'} 
</code></pre>
<ul>
<li>
<p>可以发现<code>member_id</code>已经被我们删掉了</p>
</li>
<li>
<p>删除表</p>
</li>
</ul>
<pre><code class="language-shell"># 先disable
hbase(main):011:0&gt; disable 'member'
# 再drop
hbase(main):012:0&gt; drop 'member'
# 此时再查看所有表
hbase(main):013:0&gt; list
=&gt; []
</code></pre>
<h3 id="32-dml操作">3.2 DML操作</h3>
<ol>
<li>
<p>为了方便，重新创建一张表</p>
<pre><code class="language-shell"># 表名为member，列族为address、info
create 'member','address','info'
</code></pre>
</li>
<li>
<p>创建/修改/删除表</p>
<pre><code class="language-shell"># rowkey为行名（表名） cf为列族 column为列族中的一列
插入数据： put 表名,rowkey,cf:column,key
</code></pre>
</li>
<li>
<p>实际语句如下</p>
<pre><code class="language-shell">put 'member','3z','info:age','23'
put 'member','3z','info:birthday','1996-07-31'
</code></pre>
</li>
<li>
<p>查看member中数据</p>
<pre><code class="language-shell">scan 'member'
# 返回结果
ROW					COLUMN+CELL
3z					column=info:age, timestamp=12341241212, value=23
3z					column=info:birthday, timestamp=12341241213, value=1996-07-31
</code></pre>
</li>
<li>
<p>获取某一行的数据</p>
<pre><code class="language-shell"># 获取所有3z的数据
get 'member','3z'
# 返回结果
COLUMN                            CELL                                                                                          
 info:age                         timestamp=1577955149575, value=23
 info:birthday                    timestamp=1577955128970, value=1996-07-31
</code></pre>
</li>
<li>
<p>修改某一列</p>
<pre><code class="language-shell">put 'member','3z','info:age','18'
# 获取当前年龄
get 'member','3z','info:age'
# 返回结果
COLUMN                            CELL
 info:age                         timestamp=1577955321212, value=18
# age已经被更新
</code></pre>
</li>
<li>
<p>删除某一列</p>
<pre><code class="language-shell">delete 'member','3z','info:birthday'
# 再查看3z的信息
get 'member','3z'
# 返回结果
COLUMN                            CELL
 info:age                         timestamp=1577955321212, value=18
# 删除成功
</code></pre>
</li>
<li>
<p>统计一下几行</p>
<pre><code class="language-shell">count 'member'
# 返回结果
==&gt; 1
</code></pre>
</li>
<li>
<p>删除某个一整行</p>
<pre><code class="language-shell">deleteall 'member','3z'
</code></pre>
</li>
<li>
<p>清空一张表</p>
<pre><code class="language-shell">truncate 'member'
# 会先自己disable 在truncate
Truncating 'member' table (it may take a while):
 - Disabling table...
 - Truncating table...
0 row(s) in 3.4130 seconds
</code></pre>
</li>
</ol>
<h2 id="4-hbase-api开发javascala">4. HBase API开发：Java/Scala</h2>
<ol>
<li>
<p><code>maven:pom.xml</code>：良好的网络支持</p>
<pre><code class="language-java">package com.zth.bigdata.hbase;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;

import java.io.IOException;

/**
 * Author: 3zZ.
 * Date: 2020/1/11 6:14 下午
 */
public class HbaseApp {
    Connection connection = null;
    Table table = null;
    Admin admin = null;

    String tableName = &quot;3z_hbase_java_api&quot;;

    @Before
    public void setUp() {
        Configuration configuration = new Configuration();
        configuration.set(&quot;hbase.rootdir&quot;, &quot;hdfs://localhost:8020/hbase&quot;);
        configuration.set(&quot;hbase.zookeeper.quorum&quot;, &quot;localhost:2181&quot;);
        try {
            connection = ConnectionFactory.createConnection(configuration);
            admin = connection.getAdmin();

            Assert.assertNotNull(connection);
            Assert.assertNotNull(admin);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Test
    public void getConnection() {
    }

    @Test
    public void createTable() throws Exception {
        TableName table = TableName.valueOf(tableName);
        if (admin.tableExists(table)) {
            System.out.println(tableName + &quot;已经存在&quot;);
        } else {
            HTableDescriptor descriptor = new HTableDescriptor(table);
            descriptor.addFamily(new HColumnDescriptor(&quot;info&quot;));
            descriptor.addFamily(new HColumnDescriptor(&quot;address&quot;));
            admin.createTable(descriptor);
            System.out.println(tableName + &quot;创建成功&quot;);
        }
    }

    @Test
    public void queryTableInfos() throws Exception {
        HTableDescriptor[] tables = admin.listTables();
        if (tables.length &gt; 0) {
            for (HTableDescriptor table : tables) {
                System.out.println(table.getNameAsString());
                HColumnDescriptor[] columnDescriptors = table.getColumnFamilies();
                for (HColumnDescriptor hColumnDescriptor : columnDescriptors) {
                    System.out.println(&quot;\t&quot; + hColumnDescriptor.getNameAsString());
                }
            }
        }
    }

    @Test
    public void testPut() throws Exception {
        table = connection.getTable(TableName.valueOf(tableName));
        Put put = new Put(Bytes.toBytes(&quot;3z&quot;));
        // 通过PUT设置要添加数据的CF、qualifier、value
        put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(&quot;24&quot;));
        put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;birthday&quot;), Bytes.toBytes(&quot;731&quot;));
        put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;company&quot;), Bytes.toBytes(&quot;HIT&quot;));

        put.addColumn(Bytes.toBytes(&quot;address&quot;), Bytes.toBytes(&quot;country&quot;), Bytes.toBytes(&quot;CN&quot;));
        put.addColumn(Bytes.toBytes(&quot;address&quot;), Bytes.toBytes(&quot;province&quot;), Bytes.toBytes(&quot;BJ&quot;));
        put.addColumn(Bytes.toBytes(&quot;address&quot;), Bytes.toBytes(&quot;city&quot;), Bytes.toBytes(&quot;BJ&quot;));
        //  将数据put到hbase中去
        table.put(put);
    }

    @Test
    public void testUpdate() throws Exception {
        table = connection.getTable(TableName.valueOf(tableName));
        Put put = new Put(Bytes.toBytes(&quot;2z&quot;));
        put.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(&quot;25&quot;));
        table.put(put);
    }

    @Test
    public void testGet01() throws Exception {
        table = connection.getTable(TableName.valueOf(tableName));
        Get get = new Get(&quot;3z&quot;.getBytes());
        get.addColumn(Bytes.toBytes(&quot;info&quot;), Bytes.toBytes(&quot;age&quot;));
        Result result = table.get(get);
        printResult(result);
    }
    @Test
    public void testScan01() throws Exception{
        table = connection.getTable(TableName.valueOf(tableName));
        Scan scan = new Scan();
        ResultScanner rs = table.getScanner(scan);
        for (Result result: rs){
            printResult(result);
        }
    }

    public void printResult(Result result) {
        for (Cell cell : result.rawCells()) {
            System.out.println(Bytes.toString(result.getRow()) + &quot;\t&quot; +
                    Bytes.toString(CellUtil.cloneFamily(cell)) + &quot;\t&quot; +
                    Bytes.toString(CellUtil.cloneQualifier(cell)) + &quot;\t&quot; +
                    Bytes.toString(CellUtil.cloneValue(cell)) + &quot;\t&quot; +
                    cell.getTimestamp()
            );
        }
    }

    @After
    public void tearDown() {
        try {
            connection.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
</li>
<li>
<p>小结</p>
<ul>
<li>
<p><code>Connection</code></p>
</li>
<li>
<p><code>Admin</code></p>
</li>
<li>
<p><code>HTableDescriptor</code></p>
</li>
<li>
<p><code>HcolumnDescriptor</code></p>
</li>
<li>
<p>创建表</p>
</li>
<li>
<p>删除表</p>
</li>
<li>
<p>添加记录：单挑、多条</p>
</li>
<li>
<p>修改记录</p>
</li>
<li>
<p>根据<code>RowKey</code>获取单挑记录</p>
</li>
<li>
<p><code>Scan</code>：空、起始、起始结尾、<code>Get</code></p>
</li>
<li>
<p><code>Filter</code> : <code>RowFilter</code>、<code>PrefixFilter</code>、<code>FilterList</code></p>
</li>
</ul>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（7）---- Scala隐式转换]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-7</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-7">
        </link>
        <updated>2020-01-10T16:34:35.000Z</updated>
        <content type="html"><![CDATA[<h1 id="scala隐式转换">Scala隐式转换</h1>
<h2 id="1-隐式转换概念">1. 隐式转换概念</h2>
<ul>
<li>隐式转换就是将一个类赋予另外一个类中的属性和能力</li>
</ul>
<h2 id="2-例子">2. 例子</h2>
<ul>
<li>将所有隐式转换的方法单独放到一个文件中</li>
</ul>
<pre><code class="language-scala">// ImplicitApp.scala
import java.io.File
/**
 * Author: 3zZ.
 * Date: 2020/1/10 11:15 下午
 */
object ImplicitAspect {
  // 定义隐式转换函数即可
  // 案例1 将只有eat方法的普通人变成有fly方法的超人
  implicit def man2superman(man:Man): Superman = new Superman(man.name)
  // 案例2 为File对象添加直接读的方法
  implicit def file2Richfile(file: File): Richfile = new Richfile(file)
}
</code></pre>
<ul>
<li>在需要使用的文件进行引入</li>
</ul>
<pre><code class="language-scala">import java.io.File
import ImplicitAspect._
/**
 * Author: 3zZ.
 * Date: 2020/1/10 11:00 下午
 */
object ImplicitApp extends App {
  // 定义隐式转换函数即可
  // 案例1
  val man = new Man(&quot;3z&quot;)
  man.fly() // 能够成功飞行
  // 案例2 为File对象添加直接读的方法
  val file = new File(&quot;/Users/3zz/Desktop/test.txt&quot;)
  file.read() // 能够正常读出文件
}
class Man(val name: String) {
  def eat(): Unit = {
    println(s&quot;man $name is eating&quot;)
  }
}
class Superman(val name: String) {
  def fly(): Unit = {
    println(s&quot;superman $name is flying&quot;)
  }
}
class Richfile(val file:File){
  def read() ={
    scala.io.Source.fromFile(file.getPath).mkString
  }
}
</code></pre>
<h2 id="3-隐式参数例子">3. 隐式参数例子</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 11:00 下午
 */
object ImplicitApp extends App {
  implicit val test = &quot;test&quot;
  def testParam(implicit name:String ): Unit ={
    println(name)
  }
//  testParam 什么都不填会报错 (如果在上面定义了test 就不会报错)
//  testParam(&quot;123&quot;) 正常输出 123
  implicit val name1: String = &quot;implicit_name&quot;
  testParam // 此时有了implicit 就不会报错 正常输出 implicit_name
  testParam(&quot;3z&quot;) // 输出 3z
  implicit val s1 = &quot;s1&quot;
  implicit val s2 = &quot;s3&quot;
  testParam // 此时会报错 因为有两个不确定
}
</code></pre>
<h2 id="4-隐式类例子">4. 隐式类例子</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 11:32 下午
 */
object ImplicitClassApp extends App {
  implicit class Cal(x:Int){
    def add(a:Int) = a + x
  }
  // 1本身是没有add方法的
  // 上面的隐式类为所有的Int类型添加了add方法
  println(1.add(3)) // 4
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（6）---- Scala函数高级操作]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-6</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-6">
        </link>
        <updated>2020-01-06T16:31:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="scala-函数高级操作">Scala 函数高级操作</h2>
<h2 id="1-字符串高级操作">1. 字符串高级操作</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 6:59 下午
 */
object StringApp extends App{
  val s = &quot;Hello:&quot;
  val name = &quot;3z&quot;
  println(s&quot;Hello:${name}&quot;) // 插值表达式
  val b =
    &quot;&quot;&quot;
      |这是一个多行字符串
      |hello
      |world
      |&quot;&quot;&quot;.stripMargin
  println(b)
}
// 输出
Hello:3z

这是一个多行字符串
hello
world
</code></pre>
<h2 id="2-匿名函数">2. 匿名函数</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 * 匿名函数：函数是可以命名的，也可以不命名
 * (参数名：参数类型...) =&gt; 函数体
 */
object FunctionApp extends App {
  val m1 = (x:Int) =&gt; x+1
  println(m1(10)) // 11
  def add = (x:Int, y:Int) =&gt; {x+y}
  println(add(1,2)) // 3
}
</code></pre>
<h2 id="3-curry函数">3. <code>Curry</code>函数</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 */
object FunctionApp extends App {
  def sum(a:Int, b:Int) = a+b
  println(sum(1,2))
  // 将原来接收两个参数的一个函数，转换成2个
  def sum2(a:Int)(b:Int) = a + b
  println(sum(1,2))
}
</code></pre>
<h2 id="4-高阶函数">4. 高阶函数</h2>
<ol>
<li><code>map</code></li>
<li><code>filter</code></li>
<li><code>flatmap</code></li>
<li><code>foreach</code></li>
<li><code>reduce</code></li>
</ol>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 */
object FunctionApp extends App {
  val l = List(1,2,3,4,5,6,7,8)
  // map: 逐个去操作集合中的每个元素
  l.map((x:Int) =&gt; x+1)
  l.map(x =&gt; x - 1) // 如果只有一个参数 括号可以省略
  l.map(_*2).filter(_ &gt; 8).foreach(println)// 每一个元素 * 2
  l.take(4) // 取前4个
  l.reduce(_+_) // 1 + 2 = 3 + 3 = 6 + 4 = 10...
  l.reduceLeft(_-_) // ((((1-2)-3)-4)-5)
  l.reduceRight(_-_) // (1-(2-(3-(4-5))))
  l.fold(0)(_-_)
  l.foldLeft(0)(_-_)
  l.foldRight(0)(_-_)
  val f = List(List(1,2),List(3,4),List(5,6))
  f.flatten // List(1, 2, 3, 4, 5, 6)
  f.map(_.map(_*2)) // List(List(2,4),List(6,8),List(10,12))
  f.flatMap(_.map(_*2)) // List(2, 4, 6, 8, 10, 12) == flatten + map
}

</code></pre>
<ul>
<li>
<p>一个简单wordcount的案例</p>
<pre><code class="language-scala">val txt = scala.io.Source.fromFile(&quot;wordcount.txt&quot;).mkString
val txts = List(txt)
txts.flatMap(_.split(&quot;,&quot;)).map(x =&gt; (x,1)).groupBy(_._1).mapValues(_.size)
// scala.collection.immutable.Map[String,Int] = Map(world -&gt; 1, hello -&gt; 2)
</code></pre>
</li>
</ul>
<h2 id="5-偏函数">5. 偏函数</h2>
<ul>
<li>偏函数的定义：被包在花括号类内没有match的一组case语句</li>
</ul>
<pre><code class="language-scala">package com.zth.fun

import scala.util.Random

/**
 * Author: 3zZ.
 * Date: 2020/1/10 10:49 下午
 * 偏函数：被包在花括号类内没有match的一组case语句
 */
object PartitalFunctionApp extends App {
  // 普通match函数
  val names = Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)
  val name = names(Random.nextInt(names.length))
  name match {
    case &quot;a&quot; =&gt; println(&quot;1&quot;)
    case &quot;b&quot; =&gt; println(&quot;2&quot;)
    case _ =&gt; println(&quot;others&quot;)
  }
  // 偏函数
  // A: 输入参数类型 B: 输出参数类型
  def sayChinese:PartialFunction[String, String] = {
    case &quot;a&quot; =&gt; &quot;1&quot;
    case &quot;b&quot; =&gt; &quot;2&quot;
    case _ =&gt; &quot;others&quot;
  }
  println(sayChinese(&quot;a&quot;))
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（5）---- Scala集合]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-5</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-5">
        </link>
        <updated>2020-01-04T16:29:40.000Z</updated>
        <content type="html"><![CDATA[<h1 id="scala集合">Scala集合</h1>
<h2 id="1-数组">1. 数组</h2>
<h3 id="11-定长数组array">1.1 定长数组<code>Array</code></h3>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/8 7:56 下午
 */
object ArrayApp extends App {
  val a = new Array[String](5) // Array(null,...null)
  a.length // 5
  a(1) = &quot;hello&quot;
  a(1) // String = &quot;hello&quot;
  val b = Array(&quot;hadoop&quot;, &quot;spark&quot;, &quot;storm&quot;)
  b(1) = &quot;flink&quot;
  b // Array(hadoop, flink, storm)
  val c = Array(2,3,4,5,6,7,8,9)
  c.sum // Int = 44
  c.min // Int = 9
  c.max // Int = 2
  c.mkString // String = 23456789
  c.mkString(&quot;,&quot;) //String = 2,3,4,5,6,7,8,9
  c.mkString(&quot;&lt;&quot;,&quot;,&quot;,&quot;&gt;&quot;) // String = &lt;2,3,4,5,6,7,8,9&gt;
  c.toString // String = [I@44e3760b
}
</code></pre>
<h3 id="12-变长数组arraybuffer">1.2 变长数组<code>ArrayBuffer</code></h3>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/8 7:56 下午
 */
object ArrayApp extends App {
  val c = scala.collection.mutable.ArrayBuffer[Int]()
  c += 1 // ArrayBuffer(1)
  c += (2,3,4,5) // ArrayBuffer(1, 2, 3, 4, 5)
  c ++= Array(6,7,8) // ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8)
  c.insert(0,0) // ArrayBuffer(0, 1, 2, 3, 4, 5, 6, 7, 8)
  c.remove(1) // ArrayBuffer(0, 2, 3, 4, 5, 6, 7, 8)
  c.remove(0,3) // ArrayBuffer(4, 5, 6, 7, 8)
  c.trimEnd(2) // ArrayBuffer(4, 5, 6)
  c.toArray.mkString // 456(Array类型)
  for(ele &lt;- c){
    println(ele) // 遍历 4 5 6
  }
  for(i &lt;- (0 until c.length).reverse) {
    println(c(i)) // 逆序 6 5 4
  }
}
</code></pre>
<h2 id="2-list">2. List</h2>
<ul>
<li>有序的</li>
<li>可以重复的</li>
</ul>
<h3 id="21-nil是什么">2.1 Nil是什么</h3>
<pre><code class="language-scala">scala&gt; Nil
scala.collection.immutable.Nil.type = List()
</code></pre>
<ul>
<li><code>Nil</code>就是一个空的<code>List</code></li>
</ul>
<h3 id="22-list使用">2.2 List使用</h3>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/9 4:57 下午
 */
object ListApp extends App {
  val l = List(1,2,3,4,5) // l: List[Int] = List(1, 2, 3, 4, 5)
  l.head // Int = 1
  l.tail // List[Int] = List(2, 3, 4, 5)
  val l2 = 1 :: Nil // l2: List[Int] = List(1)
  val l3 = 2 :: l2 //  l3: List[Int] = List(2, 1)
  val l4 = 1 :: 2 :: 3 :: Nil // l4: List[Int] = List(1, 2, 3)
  val l5 = scala.collection.mutable.ListBuffer[Int]()
  l5 +=  2 // ListBuffer(2)
  l5 += (3,4,5) // ListBuffer(2, 3, 4, 5)
  l5 ++= List(6,7,8) // ListBuffer(2, 3, 4, 5, 6, 7, 8)
  l5 -= 2 // ListBuffer(3, 4, 5, 6, 7, 8)
  l5 -= (1,4) // ListBuffer(2, 3, 5, 6, 7, 8)
  l5 --= List(2,3,5,6) // ListBuffer(7, 8)
  l5.toList // List[Int] = List(7, 8)
  l5.toArray // Array[Int] = Array(1, 3, 4, 5)
  l5.head // Int = 1
  l5.isEmpty // Boolean = false
  l5.tail // scala.collection.mutable.ListBuffer[Int] = ListBuffer(3, 4, 5)
  l5.tail.head // Int = 3
  
  def sum(nums:Int*):Int = {
    if(nums.length == 0){
      0
    } else{
      nums.head + sum(nums.tail:_*) // 自动把Seq转换为Int*
    }
  }
  sum(1,2,3,4) // Int = 10
}
</code></pre>
<h2 id="3-set">3. Set</h2>
<ul>
<li>无序的</li>
<li>不可重复的</li>
</ul>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/9 6:24 下午
 */
object SetApp extends App{
  val set = scala.collection.mutable.Set[Int]()
  set += 1 // set.type = Set(1)
  set += (2,1) // set.type = Set(1,2)
}

</code></pre>
<ul>
<li>其他用法基本与<code>List</code>相同</li>
</ul>
<h2 id="4-map">4. Map</h2>
<h2 id="5-option-some-none">5. Option &amp; Some &amp; None</h2>
<h2 id="6-tuple">6. Tuple</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（4）---- Scala模式匹配]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-4</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-4">
        </link>
        <updated>2020-01-03T16:28:06.000Z</updated>
        <content type="html"><![CDATA[<h1 id="scala-模式匹配">Scala 模式匹配</h1>
<h2 id="1-基本模式匹配">1. 基本模式匹配</h2>
<ol>
<li>
<p><code>Java</code>中： 对一个值进行条件判断，返回针对不同的条件进行不同的处理：<code>switch case</code></p>
</li>
<li>
<p><code>scala</code>中：</p>
<pre><code class="language-scala">变量 match {
  case value1 ==&gt; 代码1
  case value2 ==&gt; 代码2
  ....
  case _ =&gt; 代码N
}
</code></pre>
</li>
<li>
<p>一个栗子</p>
<pre><code class="language-scala">import scala.util.Random
/**
 * Author: 3zZ.
 * Date: 2020/1/10 12:10 上午
 */
object MatchApp extends App {
  val names = Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)
  val name = names(Random.nextInt(names.length))
  name match{
    case &quot;a&quot; =&gt; println(1)
    case &quot;b&quot; =&gt; println(2)
    case _ =&gt; println(&quot;不知道&quot;)
  }
  def judgeGrade(grade: String): Unit ={
    grade match{
      case &quot;A&quot; =&gt; println(&quot;Excellent..&quot;)
      case &quot;B&quot; =&gt; println(&quot;Good..&quot;)
      case &quot;C&quot; =&gt; println(&quot;Just so so..&quot;)
      case _ =&gt; println(&quot;u need worker harder&quot;)
    }
  }
  judgeGrade(&quot;A&quot;)
  judgeGrade(&quot;C&quot;)
  judgeGrade(&quot;G&quot;)
}
// 输出结果
1
Excellent..
Just so so..
u need worker harder
</code></pre>
</li>
</ol>
<h2 id="2-加条件">2. 加条件</h2>
<ul>
<li>
<p>双重过滤</p>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 12:10 上午
 */
object MatchApp extends App {
  def judgeGrade(name:String, grade: String): Unit ={
    grade match{
      case &quot;A&quot; =&gt; println(&quot;Excellent..&quot;)
      case &quot;B&quot; =&gt; println(&quot;Good..&quot;)
      case &quot;C&quot; =&gt; println(&quot;Just so so..&quot;)
      case _ if(name == &quot;lisi&quot;) =&gt; println(name + &quot; u need worker harder&quot;)
      case _  =&gt; println(&quot;u need worker harder&quot;)
    }
  }
  judgeGrade(&quot;zhangsan&quot;,&quot;D&quot;)
  judgeGrade(&quot;lisi&quot;,&quot;D&quot;)// 双重过滤
}
// 输出
u need worker harder
lisi u need worker harder
</code></pre>
</li>
</ul>
<h2 id="3-数组array中的过滤">3. 数组(Array)中的过滤</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 12:10 上午
 */
object MatchApp extends App {
  def greeting(array: Array[String]): Unit = {
    array match {
      case Array(&quot;zhangsan&quot;) =&gt; println(&quot;hello zhangsan&quot;)
      case Array(x, y) =&gt; println(&quot;hi: &quot; + x +&quot; and &quot; + y)
      case Array(&quot;zhangsan&quot;, _*) =&gt; println(&quot;hi: zhangsan and other&quot;)
      case _ =&gt; println(&quot;hi everybody&quot;)
    }
  }
  greeting(Array(&quot;zhangsan&quot;))
  greeting(Array(&quot;zhangsan&quot;, &quot;lisi&quot;))
  greeting(Array(&quot;zhangsan&quot;, &quot;lisi&quot;, &quot;wangwu&quot;))
}
// 返回结果
hello zhangsan
hi: zhangsan and lisi
hi: zhangsan and other
</code></pre>
<h2 id="4-list中的过滤">4. List中的过滤</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 12:10 上午
 */
object MatchApp extends App {
  def greeting(list: List[String]): Unit = {
    list match {
      case &quot;zhangsan&quot; :: Nil =&gt; println(&quot;Hi: zhangsan&quot;)
      case x :: y :: Nil =&gt; println(&quot;Hi:&quot; + x + &quot; , &quot; + y)
      case &quot;zhangsan&quot;::tail =&gt; println(&quot;Hi: zhangsan and others&quot;)
      case _ =&gt; println(&quot;hi: everyone&quot;)
    }
  }
  greeting(List(&quot;zhangsan&quot;))
  greeting(List(&quot;zhangsan&quot;,&quot;lisi&quot;))
  greeting(List(&quot;zhangsan&quot;,&quot;lisi&quot;,&quot;wangwu&quot;))
  greeting(List(&quot;wangwu&quot;,&quot;zhangsan&quot;,&quot;lisi&quot;))
}
// 返回
Hi: zhangsan
Hi: zhangsan , lisi
Hi: zhangsan and others
hi: everyone
</code></pre>
<h2 id="5-类型匹配">5. 类型匹配</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 12:10 上午
 */
object MatchApp extends App {
  def matchType(obj: Any): Unit = {
    obj match {
      case x: Int =&gt; println(&quot;Int&quot;)
      case s:String =&gt; println(&quot;String&quot;)
      case m:Map[_,_] =&gt; m.foreach(println)
      case _ =&gt; println(&quot;other type&quot;)
    }
  }
  matchType(1)
  matchType(&quot;1&quot;)
  matchType(Map(&quot;name&quot; -&gt; &quot;a&quot;))
  matchType(1f)
}
// 返回
Int
String
(name,a)
other type
</code></pre>
<h2 id="6-异常处理">6. 异常处理</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 1:26 上午
 */
object ExceptionApp extends App {
  try {
    val i = 10 / 0
    println(i)
  } catch {
    case e: ArithmeticException =&gt; println(&quot;除数不能为0&quot;)
    case e: Exception =&gt; println(e.getMessage)
  } finally {
    // 释放资源
  }
}
</code></pre>
<ul>
<li>在catch中判断异常</li>
<li>在finally中释放资源</li>
</ul>
<h2 id="7-case-class中的匹配">7. Case Class中的匹配</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/10 1:26 上午
 */
object ExceptionApp extends App {
  def caseclassMatch(person: Person): Unit ={
    person match{
      case CTO(name, floor) =&gt; println(&quot;CTO name is &quot;+name+&quot; ,floor: &quot;+ floor)
      case Employee(name, floor) =&gt; println(&quot;Employee name is &quot;+name+&quot; ,floor: &quot;+ floor)
      case _ =&gt; println(&quot;other&quot;)
    }
  }
  class Person
  case class CTO(name:String, floor:String) extends Person
  case class Employee(name:String, floor:String) extends Person
  case class Other(name:String) extends Person
  caseclassMatch(CTO(&quot;3zz&quot;,&quot;22&quot;))
  caseclassMatch(Employee(&quot;zhangsan&quot;, &quot;2&quot;))
  caseclassMatch(Other(&quot;lisi&quot;))
}
// 返回
CTO name is 3zz ,floor: 22
Employee name is zhangsan ,floor: 2
other
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（3） ---- Scala对象]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-3</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-3">
        </link>
        <updated>2020-01-03T15:42:39.000Z</updated>
        <content type="html"><![CDATA[<h1 id="scala面向对象">Scala面向对象</h1>
<h2 id="1-面向对象概述">1. 面向对象概述</h2>
<ol>
<li>Java / Scala OO(Objecet Orientaed)
<ul>
<li>封装：属性、方法封装到类中</li>
<li>继承：父类和子类之间的关系</li>
<li>多态：父类引用指向子类对象（重要）</li>
</ul>
</li>
</ol>
<h2 id="2-类的定义与使用">2. 类的定义与使用</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 4:55 下午
 */
object SimpleObjectApp {
  def main(args: Array[String]): Unit = {
    val person = new People()
    person.name = &quot;messi&quot;
//    person.age = 30
    println(person.name + &quot;..&quot; + person.age)
    println(&quot;invoke eat method:&quot;+person.eat())
    person.watchTv(&quot;basailuona&quot;)
    person.sex()
  }
}
class People{
  // 定义属性
  // var可以自动生成 getter 和 setter
  // _ 是占位符
  var name:String = _
  // val只能自动生成 getter
  val age:Int = 10
  private [this] val gender = &quot;male&quot;
  // 定义方法
  def eat():String = {
    name+ &quot;eat...&quot;
  }
  def sex(): Unit ={
    println(&quot;gender is &quot; + gender)
  }
  def watchTv(teamName:String): Unit ={
    println(name + &quot;is watching &quot; + teamName)
  }
}
// 返回
messi..10
invoke eat method:messieat...
messiis watching basailuona
gender is male
</code></pre>
<ul>
<li>占位符<code>_</code>
<ul>
<li>定义占位符必须使用<code>var</code></li>
<li>定义之前必须先确定变量的类型</li>
</ul>
</li>
<li><code>private [this]</code>关键字的变量
<ul>
<li>只能在类的内部被拿到</li>
</ul>
</li>
</ul>
<h2 id="3-构造器">3. 构造器</h2>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 6:23 下午
 */
object ConstructorApp {
  def main(args: Array[String]): Unit = {
    val person = new Person(&quot;zhangsan&quot;, 30)
    println(person.school + &quot;: &quot;+person.name+&quot; : &quot;+ person.age)
    val person2 = new Person(&quot;3zz&quot;, 18,&quot;M&quot;)
    println(person2.school + &quot;: &quot;+person2.name+&quot; : &quot;+ person2.age+&quot;:&quot;+person2.gender)
  }
}
// 主构造器
class Person(val name:String, val age:Int){
  println(&quot;Constructor enter..&quot;)
  val school = &quot;ustc&quot;
  var gender:String = _
  // 附属构造器
  def this(name:String, age:Int, gender:String){
    this(name, age)// 附属构造器的第一行代码必须要调用主构造器或者其他附属构造器
    this.gender = gender
  }
  println(&quot;Constructor leave..&quot;)
}
// 返回结果
Constructor enter..
Constructor leave..
ustc: zhangsan : 30
Constructor enter..
Constructor leave..
ustc: 3zz : 18:M
</code></pre>
<ul>
<li>主构造器
<ul>
<li>class关键字后面括号内的内容</li>
</ul>
</li>
<li>附属构造器
<ul>
<li>类内部的<code>this()</code>方法，需要在第一行调用主构造器或者其他附属构造器</li>
</ul>
</li>
<li>需要注意的是，如果主构造器中的属性没有<code>val</code>或者<code>var</code>，类外部无法调用该属性</li>
</ul>
<h2 id="4-继承与重写">4. 继承与重写</h2>
<ol>
<li>继承</li>
</ol>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 6:23 下午
 */
object ConstructorApp {
  def main(args: Array[String]): Unit = {
    val student = new Student(&quot;3z&quot;,18,&quot;CS&quot;)
    println(student.name+&quot; : &quot; + student.major)
  }
}
// 主构造器
class Person(val name:String, val age:Int){
  println(&quot;Constructor person enter..&quot;)
  val school = &quot;ustc&quot;
  var gender:String = _
  // 附属构造器
  def this(name:String, age:Int, gender:String){
    this(name, age)// 附属构造器的第一行代码必须要调用主构造器或者其他附属构造器
    this.gender = gender
  }
  println(&quot;Constructor person leave..&quot;)
}
class Student(name:String, age:Int,val major:String) extends Person(name, age){
  println(&quot;Constructor student enter..&quot;)
  println(&quot;Constructor student leave..&quot;)
}
</code></pre>
<ul>
<li>继承的时候还是属性需要注意
<ul>
<li>父类已经有的前面可以没有关键字</li>
<li>父类没有的需要添加<code>val</code>或者<code>var</code></li>
</ul>
</li>
</ul>
<ol start="2">
<li>重写：使用<code>override</code>关键字</li>
</ol>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 6:23 下午
 */
object ConstructorApp {
  def main(args: Array[String]): Unit = {
    val student = new Student(&quot;3z&quot;,18,&quot;CS&quot;)
    println(student.name+&quot; : &quot; + student.major)
    println(student.toString)
  }
}
// 主构造器
class Person(val name:String, val age:Int){
  println(&quot;Constructor person enter..&quot;)
  val school = &quot;ustc&quot;
  println(&quot;Constructor person leave..&quot;)
}
class Student(name:String, age:Int,val major:String) extends Person(name, age){
  println(&quot;Constructor student enter..&quot;)
  // 重写父类中的school属性
  override val school = &quot;tsing&quot;
  // 重写Object类中的toString()方法
  override def toString: String = {
    &quot;name: &quot; + name +&quot;age :&quot;+age+&quot;school: &quot; + school
  }
  println(&quot;Constructor student leave..&quot;)
}
// 返回结果
Constructor person enter..
Constructor person leave..
Constructor student enter..
Constructor student leave..
3z : CS
name: 3zage :18school: tsing
</code></pre>
<h2 id="5-抽象类">5. 抽象类</h2>
<ol>
<li>类的一个或者多个方法没有完整的实现（只有定义，没有实现）</li>
</ol>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 10:01 下午
 */
object AbstractApp {
  def main(args: Array[String]): Unit = {
    val student = new Student2()
    println(student.name)
    student.speak
  }
}
abstract class Person2{
  def speak
  val name:String
  val age:Int
}
// 需要重写抽象类中的方法和属性
class Student2 extends Person2 {
  override def speak: Unit = {
    println(&quot;speak&quot;)
  }
  override val name: String = &quot;3z&quot;
  override val age: Int = 18
}
</code></pre>
<h2 id="6-伴生类与apply">6. 伴生类与Apply</h2>
<ol>
<li>伴生类与伴生对象</li>
</ol>
<pre><code class="language-scala">/**
 * 如果有一个class， 还有一个与class同名的object
 * 那么就称这个object是class的伴生对象，class是object的伴生类
 */
// 伴生类
class ApplyTest{

}
// 伴生对象
object ApplyTest{

}
</code></pre>
<ol start="2">
<li>
<p><code>apply</code>方法</p>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 10:33 下午
 */
object ApplyApp {
  def main(args: Array[String]): Unit = {
    for (i &lt;- 1 to 10) {
      ApplyTest.incr
    }
    println(ApplyTest.count) // 说明object本身是一个单例对象
    val b = ApplyTest() // ==&gt; 默认调用 Object.apply 方法
    println(&quot;---------------------------&quot;)
    val c = new ApplyTest()// 类名() ====&gt; Class.apply()
    println(c) // com.zth.fun.ApplyTest@68c4039c
    c()// 对象() ====&gt; Object.apply()
    // class applytest apply...
  }
}

/**
 * 如果有一个class， 还有一个与class同名的object
 * 那么就称这个object是class的伴生对象，class是object的伴生类
 */
// 伴生类
class ApplyTest {
  def apply() = {
    println(&quot;class applytest apply...&quot;)
  }
}
// 伴生对象
object ApplyTest {
  println(&quot;object applytest enter..&quot;)
  var count = 0
  def incr = {
    count += 1
  }
  // 最佳实践：在Object的apply方法中去new Class
  def apply() = {
    println(&quot;object applytest apply&quot;)
    // 在object中的apply中new class
    new ApplyTest
  }
  println(&quot;object applytest leave..&quot;)
}
// 返回结果
object applytest enter..
object applytest leave..
object applytest apply
---------------------------
com.zth.fun.ApplyTest@68c4039c
class applytest apply...
</code></pre>
<ul>
<li>伴生对象<code>object</code>本身是一个单例对象，只会被调用一次</li>
<li><code>类名()</code> ====&gt; <code>Class.apply()</code></li>
<li><code>对象()</code> ====&gt; <code>Object.apply()</code></li>
<li><code>apply</code>方法的最佳实践是在伴生对象的<code>apply</code>方法中<code>new</code> 一个伴生类</li>
</ul>
</li>
</ol>
<h2 id="7-case-class">7. Case Class</h2>
<ol>
<li>通常用在模式匹配里面</li>
</ol>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/3 11:23 下午
 */
// 通常用在模式匹配里面
object CaseClassApp {
  def main(args: Array[String]): Unit = {
    println(Dog(&quot;wangcai&quot;).name)
  }
}
// case class不用new
case class Dog(name:String)
</code></pre>
<h2 id="8-trait">8. Trait</h2>
<ol>
<li>
<p>相当于<code>Java</code>中的<code>interface</code></p>
</li>
<li>
<p><code>Scala</code>中如何实现多个接口的实现？</p>
<pre><code class="language-scala">trait xxx extends aTrait with BTrait
// 实际例子
class SparkConf(loadDefaults: Boolean)
	extends Cloneable with Logging with Serializable
</code></pre>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scala学习笔记（2） ---- Scala函数]]></title>
        <id>https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-2</id>
        <link href="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post/scala-2">
        </link>
        <updated>2020-01-02T16:10:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="scala函数">Scala函数</h1>
<h3 id="1-方法的定义和使用">1. 方法的定义和使用</h3>
<figure data-type="image" tabindex="1"><img src="https://e.coding.net/zu3zz/zu3zz.coding.me.git/post-images/1577981513974.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>不需要<code>return</code></p>
</li>
<li>
<p>没有参数的时候可以不用括号</p>
<pre><code class="language-scala">def 方法名(参数名：参数类型): 返回值类型 = {
  // 括号内的叫做方法体
  
  // 方法体内的最后一行为返回值， 不需要使用return
}
</code></pre>
</li>
<li>
<p>一个例子</p>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 */
object FunctionApp {
  def main(args: Array[String]): Unit = {
    println(add(2, 3))
    println(three())
    println(three) // 没有入参的函数 调用的时候 括号是可以省略的
    sayHello(&quot;zhangsan&quot;)
    sayHello
  }
  def add(x: Int, y: Int): Int = {
    x + y // 最后一行就是返回值
  }
  def three() = 1+2
  def sayHello(): Unit ={
    println(&quot;say hello&quot;)
  }
  def sayHello(name:String): Unit ={
    println(&quot;say hello &quot;+name)
  }
}

// 返回的结果如下
5
3
3
say hello zhangsan
say hello
</code></pre>
</li>
</ol>
<h3 id="2-默认参数-命名参数">2. 默认参数、命名参数</h3>
<ol>
<li>
<p>在函数定义时，允许指定参数的默认值</p>
</li>
<li>
<p>在参数调用的时候，可以指定名字改变参数的顺序</p>
</li>
<li>
<p>一个例子</p>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 */
object FunctionApp {
  def main(args: Array[String]): Unit = {
    sayName()// 这里括号不能省略
    sayName(&quot;2yy&quot;)
    println(speed(100,10))
    println(speed(time = 5,distance = 100)) // 命名参数 可以将参数的顺序调换
  }

  def sayName(name:String=&quot;3zz&quot;): Unit ={
    println(name)
  }
  def speed(distance:Float, time:Float): Float ={
    distance / time
  }
}
// 返回的结果
3zz
2yy
10.0
20.0
</code></pre>
</li>
</ol>
<h3 id="3-可变参数">3. 可变参数</h3>
<ol>
<li>
<p><code>JDK5+</code>：可变参数</p>
</li>
<li>
<p>Spark-sql中源码</p>
<pre><code class="language-scala">// Dataset.scala文件中的select方法
@scala.annotation.varargs
def select(cols: Column*): DataFrame = withPlan {
  Project(cols.map(_.named), logicalPlan)
}

@scala.annotation.varargs
def select(col: String, cols: String*): DataFrame = select((col +: cols).map(Column(_)) : _*)
</code></pre>
</li>
<li>
<p>一个小例子</p>
<pre><code class="language-scala">/**
 * Author: 3zZ.
 * Date: 2020/1/2 10:30 下午
 */
object FunctionApp {
  def main(args: Array[String]): Unit = {
    println(sum2(1,3,5))
  }
  def sum2(numbers:Int*) = {
    var result = 0
    for(number &lt;- numbers){
      result+=number
    }
    result
  }
}
// 返回的结果
9
</code></pre>
</li>
</ol>
<h3 id="4-条件表达式">4. 条件表达式</h3>
<ul>
<li>和<code>Java</code>用法基本相同</li>
</ul>
<pre><code class="language-scala">val x = 1
if(x &gt; 0){
  true
} else {
  false
}
</code></pre>
<h3 id="5-循环表达式">5. 循环表达式</h3>
<ul>
<li>
<p><code>to</code>关键字：范围包含两边</p>
<pre><code class="language-scala">1 to 10
res0: scala.collection.immutable.Range.Inclusive = Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
// 包含了 1 和 10
// 另外一种写法
1.to(10)
res2: scala.collection.immutable.Range.Inclusive = Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
</code></pre>
</li>
<li>
<p><code>Range</code>关键字：左闭右开</p>
<pre><code class="language-scala">Range(1,10)
res1: scala.collection.immutable.Range = Range(1, 2, 3, 4, 5, 6, 7, 8, 9)
// 没有10
Range(1,10,2)
res3: scala.collection.immutable.Range = Range(1, 3, 5, 7, 9)
</code></pre>
</li>
<li>
<p><code>until</code>关键字：左闭右开</p>
<pre><code class="language-scala">1 until 10
res4: scala.collection.immutable.Range = Range(1, 2, 3, 4, 5, 6, 7, 8, 9)
</code></pre>
</li>
<li>
<p><code>for</code>循环 / <code>foreach</code>方法</p>
<pre><code class="language-scala">// 第一种方法 使用for循环
val courses = Array(&quot;1a&quot;,&quot;2b&quot;,&quot;3c&quot;,&quot;4d&quot;)
for(course &lt;- sources) {
  println(course)
}
// 输出 1a,2b,3c,4d
// 第二种方法 使用foreach
courses.foreach(course =&gt; println(course))
// =&gt; : 相当于将course作用上右边的函数 变成另外一个结果
// 输出 1a,2b,3c,4d
</code></pre>
</li>
<li>
<p><code>while</code>循环</p>
<pre><code class="language-scala">var (num, sum) = (100,0)
while(num &gt; 0){
  sum= sum + num
  num= num - 1
}
println(sum)
// 输出5050
</code></pre>
</li>
</ul>
]]></content>
    </entry>
</feed>