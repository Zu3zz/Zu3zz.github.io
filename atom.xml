<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Zu3zz.github.io</id>
    <title>zz失乐园</title>
    <updated>2019-09-10T07:35:27.272Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Zu3zz.github.io"/>
    <link rel="self" href="https://Zu3zz.github.io/atom.xml"/>
    <subtitle>Everyone Can (Not) Comprehend.</subtitle>
    <logo>https://Zu3zz.github.io/images/avatar.png</logo>
    <icon>https://Zu3zz.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, zz失乐园</rights>
    <entry>
        <title type="html"><![CDATA[Yarn系列----基础、介绍、流程]]></title>
        <id>https://Zu3zz.github.io/post/yarn-1</id>
        <link href="https://Zu3zz.github.io/post/yarn-1">
        </link>
        <updated>2019-09-10T07:31:48.000Z</updated>
        <summary type="html"><![CDATA[<p>简单介绍一下资源调度工具YARN<br>
Yet Another Resource Negotiator</p>
]]></summary>
        <content type="html"><![CDATA[<p>简单介绍一下资源调度工具YARN<br>
Yet Another Resource Negotiator</p>
<!-- more -->
<h1 id="yarn-产生背景">YARN 产生背景</h1>
<ul>
<li>
<p>MapReduce1.x ==&gt; MapReduce2.x</p>
<ul>
<li>master/slave : JobTracker/TaskTracker</li>
<li>JobTracker：单点、压力大</li>
<li>仅仅只能够支持 mapreduce 作业</li>
</ul>
</li>
<li>
<p>资源利用率</p>
<ul>
<li>所有的计算框架运行在一个集群中，共享一个集群的资源，按需分配！</li>
</ul>
</li>
</ul>
<pre><code class="language-txt">master: resource management：ResourceManager (RM)
job scheduling/monitoring：per-application ApplicationMaster (AM)
slave: NodeManager (NM)
</code></pre>
<h2 id="yarn-架构">YARN 架构</h2>
<ul>
<li>Client、ResourceManager、NodeManager、ApplicationMaster</li>
<li>master/slave: RM/NM</li>
</ul>
<h2 id="client-向-rm-提交任务-杀死任务等">Client: 向 RM 提交任务、杀死任务等</h2>
<ul>
<li>
<p>ApplicationMaster：</p>
<ul>
<li>每个应用程序对应一个 AM</li>
<li>AM 向 RM 申请资源用于在 NM 上启动对应的 Task</li>
<li>数据切分</li>
<li>为每个 task 向 RM 申请资源（container）</li>
<li>NodeManager 通信</li>
<li>任务的监控</li>
</ul>
</li>
<li>
<p>NodeManager： 多个</p>
<ul>
<li>干活</li>
<li>向 RM 发送心跳信息、任务的执行情况</li>
<li>接收来自 RM 的请求来启动任务</li>
<li>处理来自 AM 的命令</li>
</ul>
</li>
<li>
<p>ResourceManager:集群中同一时刻对外提供服务的只有 1 个，负责资源相关</p>
<ul>
<li>处理来自客户端的请求：提交、杀死</li>
<li>启动/监控 AM</li>
<li>监控 NM</li>
<li>资源相关</li>
</ul>
</li>
<li>
<p>container：任务的运行抽象</p>
<ul>
<li>memory、cpu....</li>
<li>task 是运行在 container 里面的</li>
<li>可以运行 am、也可以运行 map/reduce task</li>
</ul>
</li>
</ul>
<h2 id="yarn-执行流程">yarn 执行流程</h2>
<p><img src="https://Zu3zz.github.io/post-images/1568100871914.png" alt="yarn执行流程"></p>
<h2 id="提交自己开发的-mr-作业到-yarn-上运行的步骤">提交自己开发的 MR 作业到 YARN 上运行的步骤：</h2>
<ol>
<li>mvn clean package -DskipTests 打包 jar 包<br>
windows/Mac/Linux ==&gt; Maven</li>
<li>把编译出来的 jar 包(项目根目录/target/...jar)以及测试数据上传到服务器<br>
scp xxxx hadoop@hostname:directory</li>
<li>把数据上传到 HDFS<br>
hadoop fs -put xxx hdfspath</li>
<li>执行作业<br>
hadoop jar xxx.jar 完整的类名(包名+类名) args.....</li>
<li>到 YARN UI(8088) 上去观察作业的运行情况</li>
<li>到输出目录去查看对应的输出结果</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop()----多集群配置流程]]></title>
        <id>https://Zu3zz.github.io/post/hadoop-4</id>
        <link href="https://Zu3zz.github.io/post/hadoop-4">
        </link>
        <updated>2019-09-09T13:12:27.000Z</updated>
        <summary type="html"><![CDATA[<p>终于到了激动人心的伪(划掉分布式环节 如何将HDFS配置在多机器的集群上<br>
这篇文章会详细告诉你~</p>
]]></summary>
        <content type="html"><![CDATA[<p>终于到了激动人心的伪(划掉分布式环节 如何将HDFS配置在多机器的集群上<br>
这篇文章会详细告诉你~</p>
<!-- more -->
<h1 id="hadoop-集群规划">Hadoop 集群规划</h1>
<ul>
<li>
<p>HDFS: NN DN</p>
</li>
<li>
<p>YARN: RM NM</p>
</li>
<li>
<p>hadoop000 192.168.199.234</p>
<ul>
<li>NN RM</li>
<li>DN NM</li>
</ul>
</li>
<li>
<p>hadoop001 192.168.199.235</p>
<ul>
<li>DN NM</li>
</ul>
</li>
<li>
<p>hadoop002 192.168.199.236</p>
<ul>
<li>DN NM</li>
</ul>
</li>
</ul>
<h2 id="详细步骤">详细步骤</h2>
<ul>
<li>
<p>对每台机器</p>
<ul>
<li>
<p>修改 host 配置</p>
<ul>
<li>
<p>在/etc/hostname 下修改 hostname(hadoop000/hadoop001/hadoop002)</p>
</li>
<li>
<p>在/etc/hosts 下修改 ip 和 hostname 的映射关系</p>
<ol>
<li>192.168.199.234 hadoop000</li>
<li>192.168.199.235 hadoop001</li>
<li>192.168.199.236 hadoop002</li>
<li>192.168.199.23x localhost(试机器而定)</li>
</ol>
</li>
</ul>
</li>
<li>
<p>前置安装 ssh 进行免密码登录操作</p>
</li>
</ul>
<pre><code class="language-shell">ssh-keygen -t rsa
</code></pre>
<p>在每台 hadoop 机器上进行操作</p>
<pre><code class="language-shell">ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop000
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop001
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop002
</code></pre>
<ul>
<li>
<p>安装 java jkd</p>
<ul>
<li>首先在每台 hadoop 集群机器上部署 jdk</li>
<li>将 jkd bin 配置到系统环境变量(~/.bash_profile)</li>
<li>将 jdk 以及环境变量配置拷贝到其他节点上去(start with hadoop000)</li>
</ul>
<pre><code class="language-shell">scp -r jdk1.8.0_91 hadoop@hadoop001:~/app/
scp -r jdk1.8.0_91 hadoop@hadoop002:~/app/

scp ~/.bash_profile hadoop@hadoop001:~/
scp ~/.bash_profile hadoop@hadoop002:~/
</code></pre>
</li>
<li>
<p>Hadoop 部署</p>
<ul>
<li>hadoop-env.sh 配置: JAVA_HOME</li>
<li>hdfs-site.xml 配置:</li>
</ul>
<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
  &lt;value&gt;/home/hadoop/app/tmp/dfs/name&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
  &lt;value&gt;/home/hadoop/app/tmp/dfs/data&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li>yarn-site.xml</li>
</ul>
<pre><code class="language-xml">&lt;!--只在hadoop000机器中进行配置--&gt;
&lt;property&gt;
  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
  &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;hadoop000&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li>mapred-site.xml: 这个文件只有模板 需要自己创建</li>
</ul>
<pre><code class="language-xml">&lt;property&gt;
  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
  &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<ul>
<li>配置 slaves</li>
<li>分发 hadoop 到其他机器</li>
</ul>
<pre><code class="language-shell">scp -r hadoop-2.6.0-cdh5.15.1 hadoop@hadoop001:~/app/
scp -r hadoop-2.6.0-cdh5.15.1 hadoop@hadoop002:~/app/

scp ~/.bash_profile hadoop@hadoop001:~/
scp ~/.bash_profile hadoop@hadoop002:~/
</code></pre>
<ul>
<li>NN 格式化</li>
</ul>
<pre><code class="language-shell">hadoop namenode -format
</code></pre>
<ul>
<li>在每个机器上启动 HDFS</li>
<li>在每个机器上启动 YRAN</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hive系列(2)----内部表、外部表、实战]]></title>
        <id>https://Zu3zz.github.io/post/hive-2</id>
        <link href="https://Zu3zz.github.io/post/hive-2">
        </link>
        <updated>2019-09-09T07:48:10.000Z</updated>
        <summary type="html"><![CDATA[<p>这节咱们来点真实的<br>
hive如何创建表以及读取数据</p>
]]></summary>
        <content type="html"><![CDATA[<p>这节咱们来点真实的<br>
hive如何创建表以及读取数据</p>
<!-- more -->
<h1 id="hive-外部表-内部表">Hive 外部表、内部表</h1>
<h2 id="内部表">内部表</h2>
<p>可以通过 formatted 查看表的属性</p>
<pre><code class="language-sql">desc formattede mp2

可以看到一系列属性 其中有属性如下

Table Type: MANAGED_TABLE

MANAGED_TABLE就代emp2是一个内部表

删除emp2
drop table emp2;
</code></pre>
<p>删除表: HDFS 上的数据被删除 &amp; Meta 也被删除</p>
<h2 id="外部表">外部表</h2>
<p>创建外部表</p>
<pre><code class="language-sql">CREATE EXTERNNAL TABLE emp_external(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
location '/external/emp/';

此时表是空表 还需要加载数据
LOAD DATA LOCAL INPATH '/home/hadoop/data/emp.txt' ONVERWRITE INTO TABLE emp_external

此时通过desc查看表的属性
Table Type: EXTERNAL_TABLE
是一个外部表

drop table emp_external
</code></pre>
<p>删除表: HDFS 上的数据不被删除 &amp; Meta 上被删除<br>
安全性更好</p>
<h2 id="分区表">分区表</h2>
<p>使用分区表创建</p>
<pre><code class="language-sql">CREATE EXTERNAL TABLE track_info(
ip string,
country string,
province string,
city string,
url string,
time string,
page string
) partitioned by (day string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
location '/project/trackinfo/';
</code></pre>
<p>此时通过执行 jar 包生成 ETL 文件</p>
<p>将这个文件存储到 hive 中</p>
<pre><code class="language-sql">LOAD DATA INPATH 'hdfs://localhost:8020/project/input/etl'
OVERWRITE INTO TABLE track_info partition(day='2013-07-21');

统计总数
select count(*) from track_info where day='2013-07-21';

统计省份的个数
select province,count(*) from track_info where day='2013-07-21' group by province;

为了方便展示 创建一张表用来存储省份的信息
create table track_info_province_stat(
province string,
cnt bigint
) partitioned by (day string)
row format delimited fields terminated by '\t';

通过sql语句直接写入数据
insert overwrite table track_info_province_stat partition(day='2013-07-21') select province, count(*) as cnt from track_info where day='2013-07-21' group by province;

统计页面访问情况
select page,count(*) from track_info where day = '2013-07-21' group by page;

创建一张表用来存储页面访问信息
create table track_info_page_stat(
province string,
cnt bigint
) partitioned by (day string)
row format delimited fields terminated by '\t';

写入数据
insert overwrite table track_info_page_stat partition(day='2013-07-21') select page, count(*) as cnt from track_info where day='2013-07-21' group by page;
</code></pre>
<p>到现在为止，我们统计的数据已经在 Hive 表 track_info_province_stat<br>
而且这个表是一个分区表，后续统计报表的数据可以直接从这个表中查询<br>
也可以将 hive 表的数据导出到 RDBMS（sqoop<br>
总结一下所有的操作</p>
<ol>
<li>ETL</li>
<li>把 ETL 输出的数据加载到 track_info 分区表里</li>
<li>各个维度统计结果的数据输出到各自维度的表里 （如 track_info_province_stat）</li>
<li>将数据导出 (optional)</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hive系列(1)----概念、部署、语法]]></title>
        <id>https://Zu3zz.github.io/post/hive-1</id>
        <link href="https://Zu3zz.github.io/post/hive-1">
        </link>
        <updated>2019-09-07T12:35:32.000Z</updated>
        <summary type="html"><![CDATA[<p>慢慢学习路 一步一脚印<br>
今天带来hive学习笔记系列的第一篇</p>
]]></summary>
        <content type="html"><![CDATA[<p>慢慢学习路 一步一脚印<br>
今天带来hive学习笔记系列的第一篇</p>
<!-- more -->
<h1 id="hive-笔记">Hive 笔记</h1>
<h2 id="hive-概念">Hive 概念</h2>
<ul>
<li>
<p>统一元数据管理:</p>
<ul>
<li>Hive 数据是存放在 HDFS</li>
<li>元数据信息(记录数据的数据)是存放在 MySQL 中</li>
<li>SQL on Hadoop： Hive、Spark SQL、impala....</li>
</ul>
</li>
<li>
<p>Hive 体系架构</p>
<ul>
<li>client: shell、thrift/jdbc(server/jdbc)、WebUI(HUE/Zeppelin)</li>
<li>metastore：==&gt; MySQL<br>
database：name、location、owner....<br>
table：name、location、owner、column name/type ....</li>
</ul>
</li>
<li>
<p>Hive 部署</p>
<ol>
<li>下载（官网）</li>
<li>解压到~/app</li>
<li>添加 HIVE_HOME 到系统环境变量</li>
<li>修改配置<br>
hive-env.sh<br>
hive-site.xml</li>
<li>拷贝 MySQL 驱动包 mysql-java-connector.jar 包到$HIVE_HOME/lib 下</li>
<li>前提是要准备安装一个 MySQL 数据库，利用 yum install 安装一个 MySQL 数据库 https://www.cnblogs.com/julyme/p/5969626.html</li>
</ol>
<pre><code class="language-xml">&lt;!--hive-site.xml配置--&gt;
&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
  &lt;value&gt;jdbc:mysql://hadoop000:3306/hadoop_hive?createDatabaseIfNotExist=true&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
  &lt;value&gt;我是用户名&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
  &lt;value&gt;我是密码&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
</li>
</ul>
<h2 id="hive-的-sql-语言">Hive 的 sql 语言</h2>
<h3 id="ddl">DDL</h3>
<p>Hive Data Definition Language</p>
<pre><code class="language-shell">create、delete、alter...
</code></pre>
<p>Hive 数据抽象/结构:</p>
<pre><code class="language-ASCII">+-- database  HDFS一个目录
|   +-- table HDFS一个目录
    |   +-- data  文件
    |   +-- partition 分区表  HDFS一个文件
        |   +-- data  文件
        |   +-- bucket  分桶  HDFS一个文件
</code></pre>
<p>Hive 具体 ddl 操作</p>
<h3 id="创建数据库">创建数据库</h3>
<pre><code class="language-sql">CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name
  [COMMENT database_comment]
  [LOCATION hdfs_path]
  [WITH DBPROPERTIES (property_name=property_value, ...)];

CREATE DATABASE IF NOT EXISTS hive;

CREATE DATABASE IF NOT EXISTS hive2 LOCATION '/test/location';

CREATE DATABASE IF NOT EXISTS hive3
WITH DBPROPERTIES('creator'='pk');
</code></pre>
<p>/user/hive/warehouse 是 Hive 默认的存储在 HDFS 上的路径</p>
<h3 id="创建表">创建表</h3>
<pre><code class="language-sql">CREATE TABLE emp(
empno int,
ename string,
job string,
mgr int,
hiredate string,
sal double,
comm double,
deptno int
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
</code></pre>
<h3 id="读取本地数据">读取本地数据</h3>
<pre><code class="language-sql">LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]

LOAD DATA LOCAL INPATH '/home/hadoop/data/emp.txt' OVERWRITE INTO TABLE emp;
</code></pre>
<p>LOCAL：本地系统，如果没有 local 那么就是指的 HDFS 的路径<br>
OVERWRITE：是否数据覆盖，如果没有那么就是数据追加</p>
<pre><code class="language-sql">LOAD DATA LOCAL INPATH '/home/hadoop/data/emp.txt' OVERWRITE INTO TABLE emp;

LOAD DATA INPATH 'hdfs://hadoop000:8020/data/emp.txt' INTO TABLE emp;

INSERT OVERWRITE LOCAL DIRECTORY '/tmp/hive/'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
select empno,ename,sal,deptno from emp;
</code></pre>
<h3 id="基本统计">基本统计</h3>
<pre><code class="language-sql">select * from emp where sal between 800 and 1500 (limit(5));

select * from emp where ename in ('SMITH','KING');

select * from emp where sal is (not) null;
</code></pre>
<h3 id="聚合操作">聚合操作</h3>
<p>max/min/sum/avg</p>
<pre><code class="language-sql">select count(1) from emp where deptno = 10;

select max(sal),min(sal),sum(sal),avg(sal) from emp;
</code></pre>
<h3 id="分组函数">分组函数</h3>
<p>group by</p>
<p>出现在 select 中的字段，如果没有出现在聚合函数里，那么一定要实现在 group by 里</p>
<pre><code class="language-sql">求每个部门的平均工资
select deptno, avg(sal) from emp group by deptno;

求每个部门、工作岗位的平均工资
select deptno,job,avg(sal) from emp group by deptno, job;

求每个部门的平均工资大于2000的部门
select deptno, avg(sal) avg_sal from emp group by deptno where avg_sal &gt; 2000; 错误！！！

group by 不能同时和 where 使用
应该使用having替代where

select deptno, avg(sal) abg_sal from emp group by deptno having avg_sal &gt; 2000;
</code></pre>
<h3 id="多表操作">多表操作</h3>
<p>join</p>
<p>两个表:</p>
<ol>
<li>emp</li>
<li>dept</li>
</ol>
<pre><code class="language-sql">创建表
CREATE TABLE dept(
deptno int,
dname string,
loc string
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
加载数据
LOAD DATA LOCAL INPATH '/home/hadoop/data/dept.txt' OVERWRITE INTO TABLE dept;

select
e.empno,e.ename,e.sal,e.deptno,d.name
from emp e join dept d
on e.deptno=d.deptno
</code></pre>
<h4 id="关于-stage-0-stage-3-stage-4">关于 stage-0、stage-3、stage-4</h4>
<p>由于join是一个复杂操作，所以需要分步骤进行查询</p>
<pre><code class="language-sql">explain EXTENDED
select
e.empno,e.ename,e.sal,e.deptno,d.dname
from emp e join dept d
on e.deptno=d.deptno;
</code></pre>
<ul>
<li>stage-4 is root stage</li>
<li>stage-3 depends on stage-4</li>
<li>stage-0 depends on stage-3</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[python基础操作]]></title>
        <id>https://Zu3zz.github.io/post/python-basic</id>
        <link href="https://Zu3zz.github.io/post/python-basic">
        </link>
        <updated>2019-09-04T13:23:26.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  分享Python的一些骚操作</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  分享Python的一些骚操作</p>
<!-- more -->
<h2 id="file">file</h2>
<pre><code class="language-python">file1 = read(&quot;test.txt&quot;)
# 找到当前位置的指针
file1.tell()
# 让文件的指示指针进行偏移 第一个参数代表偏移位置 第二个参数 0代表从文件开头偏移 1代表从当前位置进行偏移 2代表从文件结尾进行偏移
file1.seek(5,0)
</code></pre>
<h2 id="error处理">error处理</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[leetcode-股票买卖问题(121,122,123,188,309,714)]]></title>
        <id>https://Zu3zz.github.io/post/leetcode-stock</id>
        <link href="https://Zu3zz.github.io/post/leetcode-stock">
        </link>
        <updated>2019-08-18T06:28:46.000Z</updated>
        <summary type="html"><![CDATA[<p>如何用一个动态规划方程解决leetcode上所有的股票买卖问题，且听我道来</p>
]]></summary>
        <content type="html"><![CDATA[<p>如何用一个动态规划方程解决leetcode上所有的股票买卖问题，且听我道来</p>
<!-- more -->
<p><strong>直接看题目188</strong></p>
<h2 id="188-买卖股票的最佳时机-iv">188. 买卖股票的最佳时机 IV</h2>
<p>给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。</p>
<p>设计一个算法来计算你所能获取的最大利润。你最多可以完成 k 笔交易。</p>
<p>注意: 你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。</p>
<p>示例 1:</p>
<pre><code>输入: [2,4,1], k = 2
输出: 2
解释: 在第 1 天 (股票价格 = 2) 的时候买入，在第 2 天 (股票价格 = 4) 的时候卖出，这笔交易所能获得利润 = 4-2 = 2 。
</code></pre>
<p>示例2：</p>
<pre><code>输入: [3,2,6,5,0,3], k = 2
输出: 7
解释: 在第 2 天 (股票价格 = 2) 的时候买入，在第 3 天 (股票价格 = 6) 的时候卖出, 这笔交易所能获得利润 = 6-2 = 4 。
     随后，在第 5 天 (股票价格 = 0) 的时候买入，在第 6 天 (股票价格 = 3) 的时候卖出, 这笔交易所能获得利润 = 3-0 = 3 。
</code></pre>
<p>对于这道题，最麻烦的无异于暴力，复杂度会变成O(2^n)。<br>
使用动态规划(dp)，可以有效的解决</p>
<p>对于一个常见的dp问题来说 通常分两步走</p>
<ol>
<li>定义状态方程</li>
<li>转移公式</li>
</ol>
<p>对于这道题，可以定义一个状态方程max_profit[i]用来记录到第i天的最大利润</p>
<pre><code class="language-c++">mp[i] = mp[i-1] + -a[i](如果买入) + a[i](如果卖出)
</code></pre>
<p>但是股票的买入需要当前手上没有股票买入<br>
同样 股票的卖出需要手上已经持有了一股的股票<br>
单纯的一维数组没有办法记录这些信息 所以需要增加一维度</p>
<pre><code class="language-c++">使用mp[i][j]
j=[0,1] // 0为可以买 1为可以卖
</code></pre>
<p>此时状态方程变为</p>
<pre><code>mp[i][0] = max(mp[i-1][0] //不交易 ,mp[i-1][1] + a[i]// 前一天卖了一股)
mp[i][1] = max(mp[i-1][1] // 不交易, mp[i-1][0] - a[i] //前一天买了一股)
</code></pre>
<p>由于188题有限制条件，即最多只能交易k次，还需要记录交易次数，还需要一维来记录交易了多少次<br>
此时状态方程变成了</p>
<pre><code>mp[i][h][k]
i 表示天数
j 表示是否持有股票
k 表示之前交易了多少次
</code></pre>
<p>此时动态规划的转移方程变成了如下所示:</p>
<pre><code class="language-c++">// 为了方便理解 把k放到了第二维

//前一天 要么不操作 要么卖掉了一股
mp[i][k][0] = max(mp[i-1][k][0], mp[i-1][k-1][1] + a[i])

//  前一天 要么不操作 要么买入了一股
mp[i][k][1] = max(mp[i-1][k][1], mp[i-1][k][0] - a[i)
</code></pre>
<p>想要求出最大的收益 只需要找到<br>
<code>mp[n-1, {0...k},0]</code>的最大值即可</p>
<h2 id="188买卖股票的最佳时机iv">188.买卖股票的最佳时机IV</h2>
<h3 id="python-solution">python solution</h3>
<pre><code class="language-python">class Solution:
    def maxProfit(self, k: int, prices: List[int]) -&gt; int:
        if not prices or not k:
            return 0
        n  = len(prices)
        # 如果k大于数组长度的一半，则可以用贪心解决
        if k &gt; n//2:
            return self.greedy(prices)
        # 动态规划
        dp = [[[0] * 2 for _ in range(k+1)] for _ in range(n)]
        res = []
        # 设置初始状态
        for i in range(k+1):
            dp[0][i][0], dp[0][i][1] = 0, -prices[0]
        # 开始两层循环
        for i in range(1,n):
            for j in range(k+1):
                if not j:
                    dp[i][j][0] = dp[i-1][j][0]
                else:
                    dp[i][j][0] = max(dp[i-1][j][0], dp[i-1][j-1][1] + prices[i])
                dp[i][j][1] = max(dp[i-1][j][1], dp[i-1][j][0] - prices[i])
        # 找到最大值
        for m in range(k+1):
            print(dp[n-1][m][0])
            res.append(dp[n-1][m][0])
        return max(res)
    def greedy(self, prices):
        res = 0
        for i in range(1,len(prices)):
            if prices[i] &gt; prices[i-1]:
                res += prices[i] - prices[i-1]
        return res
</code></pre>
<h2 id="309买卖股票的最佳时机含冻结期">309.买卖股票的最佳时机含冻结期</h2>
<p>对于这道题目 dp状态可以相应减少，因为没有次数的限制了，只需要做一个二维的dp就可以了 一个维度i是用来存储天数，另外一个维度j用来存储当前股票买卖的状态 012分别表示没有买入 买入了 以及处于冻结期</p>
<h3 id="python-solution-2">python solution</h3>
<pre><code class="language-python">class Solution:
    def maxProfit(self, prices: List[int]) -&gt; int:
        if not prices:
            return 0
        n = len(prices)
        dp = [[0] * 3 for _ in range(n)]
        # 0表示今天未持有 1表示今天持有 2表示今天处于冻结状态
        dp[0][0], dp[0][1], dp[0][2] = 0,-prices[0],0
        for i in range(1,n):
            dp[i][0] = max(dp[i-1][0], dp[i-1][2])
            dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i])
            dp[i][2] = dp[i-1][1] + prices[i]
        return max(dp[n-1][0], dp[n-1][2])
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leetcode-weeklyContest-150]]></title>
        <id>https://Zu3zz.github.io/post/leetcode-weeklycontest-150</id>
        <link href="https://Zu3zz.github.io/post/leetcode-weeklycontest-150">
        </link>
        <updated>2019-08-18T05:49:18.000Z</updated>
        <summary type="html"><![CDATA[<p>第150周的题解</p>
]]></summary>
        <content type="html"><![CDATA[<p>第150周的题解</p>
<!-- more -->
<h2 id="第一题">第一题</h2>
<h3 id="5048-拼写单词">5048. 拼写单词</h3>
<p>要求:<br>
给你一份『词汇表』（字符串数组） words 和一张『字母表』（字符串） chars。</p>
<p>假如你可以用 chars 中的『字母』（字符）拼写出 words 中的某个『单词』（字符串），那么我们就认为你掌握了这个单词。</p>
<p>注意：每次拼写时，chars 中的每个字母都只能用一次。</p>
<p>返回词汇表 words 中你掌握的所有单词的 长度之和。<br>
示例1：</p>
<pre><code>输入：words = [&quot;cat&quot;,&quot;bt&quot;,&quot;hat&quot;,&quot;tree&quot;], chars = &quot;atach&quot;
输出：6
解释： 
可以形成字符串 &quot;cat&quot; 和 &quot;hat&quot;，所以答案是 3 + 3 = 6。
</code></pre>
<p>示例2：</p>
<pre><code>输入：words = [&quot;hello&quot;,&quot;world&quot;,&quot;leetcode&quot;], chars = &quot;welldonehoneyr&quot;
输出：10
解释：
可以形成字符串 &quot;hello&quot; 和 &quot;world&quot;，所以答案是 5 + 5 = 10。
</code></pre>
<p><strong>思路：</strong><br>
直接把字符串问题转化成为一个大小为26的数组，对给定的「字母表」进行遍历，将数组的对应位置记录下每个字母出现了多少次，再循环一遍给出的「词汇表」，只要词汇表每个都比给定的字母表的数组元素小，那么就说明可以表示。</p>
<p>solution in cpp:</p>
<pre><code class="language-c++">class Solution {
public:
    int countCharacters(vector&lt;string&gt;&amp; words, string chars) {
        int s[26],t[26],i,result = 0;
        memset(s,0,sizeof(s));
        for(auto c:chars)s[c-'a']++;
        for(auto d:words){
            memset(t,0,sizeof(t));
            for(auto e:d)t[e-'a']++;
            for(i=0;i&lt;26;i++) if(s[i]&lt;t[i]) break;
            if(i==26) result+=d.size();
        }
        return result;
    }
};
</code></pre>
<h2 id="第二题">第二题</h2>
<h3 id="5052最大层内元素和">5052.最大层内元素和</h3>
<p>给你一个二叉树的根节点 root。设根节点位于二叉树的第 1 层，而根节点的子节点位于第 2 层，依此类推。</p>
<p>请你找出层内元素之和 最大 的那几层（可能只有一层）的层号，并返回其中 最小 的那个。<br>
给定一个二叉树 大概长下面这样<br>
实例：<br>
<img src="https://Zu3zz.github.io/post-images/1566107780628.jpeg" alt=""></p>
<pre><code>输入：[1,7,0,7,-8,null,null]
输出：2
解释：
第 1 层各元素之和为 1，
第 2 层各元素之和为 7 + 0 = 7，
第 3 层各元素之和为 7 + -8 = -1，
所以我们返回第 2 层的层号，它的层内元素之和最大。
</code></pre>
<p>思路：<br>
使用一个dict用来存储每一层的元素的值，每一对键值对都是层数和相对应的值的和，使用dfs遍历所有树的节点，同时将节点所在的层数传进去，传进去的同时直接访问对应的dict对应的元素,直接加起来，最后遍历一遍输出最大的值</p>
<ul>
<li>solution in cpp:</li>
</ul>
<pre><code class="language-c++">/**
 * Definition for a binary tree node.
 * struct TreeNode {
 *     int val;
 *     TreeNode *left;
 *     TreeNode *right;
 *     TreeNode(int x) : val(x), left(NULL), right(NULL) {}
 * };
 */
class Solution {
public:
    int s[10005], n;
    void dfs(TreeNode* root, int level){
        if(!root) return;
        n = max(n,level);
        s[level]+=root-&gt;val;
        dfs(root-&gt;left,level+1);
        dfs(root-&gt;right,level+1);
    }
    int maxLevelSum(TreeNode* root) {
        memset(s,0,sizeof(s));
        n = 0;
        dfs(root,1);
        int j = 1;
        for(int i = 1;i&lt;=n;i++){
            if(s[i] &gt; s[j])
                j = i;
        }
        return j;
    }
};
</code></pre>
<ul>
<li>solution in python:</li>
</ul>
<pre><code class="language-python"># Definition for a binary tree node.
# class TreeNode:
#     def __init__(self, x):
#         self.val = x
#         self.left = None
#         self.right = None

class Solution:
    
    def maxLevelSum(self, root: TreeNode) -&gt; int:
        m,res,level = {},0,0
        def dfs(root,level):
            if root == None:
                return
            if level not in m:
                m[level] = 0
            m[level]+=root.val
            dfs(root.left,level+1)
            dfs(root.right,level+1)
        dfs(root, 1)
        min_ = -sys.maxsize
        for key in m.keys():
            if m[key] &gt; min_:
                min_, res = m[key], key
        return res
</code></pre>
<h2 id="第三题">第三题</h2>
<h3 id="5053地图分析">5053.地图分析</h3>
<p>你现在手里有一份大小为 N x N 的『地图』（网格） grid，上面的每个『区域』（单元格）都用 0 和 1 标记好了。其中 0 代表海洋，1 代表陆地，你知道距离陆地区域最远的海洋区域是是哪一个吗？请返回该海洋区域到离它最近的陆地区域的距离。</p>
<p>我们这里说的距离是『曼哈顿距离』（ Manhattan Distance）：(x0, y0) 和 (x1, y1) 这两个区域之间的距离是 |x0 - x1| + |y0 - y1| 。</p>
<p>如果我们的地图上只有陆地或者海洋，请返回 -1。</p>
<p>实例1：<br>
<img src="https://Zu3zz.github.io/post-images/1566108523044.jpeg" alt="实例"></p>
<pre><code>输入：[[1,0,1],[0,0,0],[1,0,1]]
输出：2
解释： 
海洋区域 (1, 1) 和所有陆地区域之间的距离都达到最大，最大距离为 2。
</code></pre>
<p>太菜了 没做出来</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[堆排序(Heap Sort)]]></title>
        <id>https://Zu3zz.github.io/post/heap-sort</id>
        <link href="https://Zu3zz.github.io/post/heap-sort">
        </link>
        <updated>2019-08-17T10:17:56.000Z</updated>
        <summary type="html"><![CDATA[<p>堆排序真的是面试非常容易考到的一个问题了，今天就来聊聊Heap Sort。</p>
]]></summary>
        <content type="html"><![CDATA[<p>堆排序真的是面试非常容易考到的一个问题了，今天就来聊聊Heap Sort。</p>
<!-- more -->
<p>写这篇博客的原因是因为今天面试被问到了如何使用堆排序在一个百万数量级的数组中取出前k大的元素，可能是有点紧张，我大脑当场短路了，直接把二分搜索树和堆排序搞混了，真的是太丢人了，果不其然面试也挂了。</p>
<p>痛定思痛，决定自己认真的再复习和回顾一下堆排序的所有操作。</p>
<h2 id="1基本存储">1.基本存储</h2>
<p>首先从堆这个数据结构说起，堆可以做到入堆和出堆都是O(logn)的复杂度，平均时间上比起O(1)+O(n)这种组合要快出去很多。</p>
<p>首先从堆的基本形态说起，堆本质是就是一个数组，但是在存储的过程中，我们可以把它看做是一个完全二叉树:即索引为0的位置为根节点，索引为1、2的位置为根节点的子节点，下面就是一个二叉堆(Binary Heap)，对应的就是一个二叉树<br>
<img src="https://Zu3zz.github.io/post-images/1566038321792.png" alt=""><br>
可以看到，二叉堆满足性质如下，所有子节点均小于父亲节点，即<br>
<code>41&lt;62 &amp;&amp; 30&lt;62</code></p>
<p><strong>并且 二叉堆是一颗完全二叉树</strong><br>
<img src="https://Zu3zz.github.io/post-images/1566038535528.png" alt=""></p>
<p>所以上图所示的堆可以在cpp中如下所存储</p>
<pre><code class="language-c++">int arr[] = {0,62,41,30,28,16,22,13,19,17,15}
</code></pre>
<p>可以注意到这里index为0的元素没有使用，这是为了方便堆排序进行左右节点的计算规则。<br>
所以这样所有的子节点和父节点就满足如下的公式</p>
<pre><code class="language-c++">parent i = i /2;
left child i = 2 * i;
right child i = 2 * i +1;
</code></pre>
<p>本节对应代码：<br>
<strong><a href="https://github.com/Zu3zz/Learn_some_algorithm_and_data_structure/blob/master/heap-sort/01-MaxHeap/main.cpp">二叉堆的建立与基本操作</a></strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[从头梳理服务器渲染原理(SSR)]]></title>
        <id>https://Zu3zz.github.io/post/react-ssr</id>
        <link href="https://Zu3zz.github.io/post/react-ssr">
        </link>
        <updated>2019-08-14T14:54:33.000Z</updated>
        <summary type="html"><![CDATA[<p>这一次，让我们来以React为例，把服务端渲染(Server Side Render，简称“SSR”)学个明明白白。</p>
]]></summary>
        <content type="html"><![CDATA[<p>这一次，让我们来以React为例，把服务端渲染(Server Side Render，简称“SSR”)学个明明白白。</p>
<!-- more -->
<h2 id="part1实现一个基础的react组件ssr">part1：实现一个基础的React组件SSR</h2>
<p>这一部分来简要实现一个React组件的SSR。</p>
<h3 id="一-ssr-vs-csr">一. SSR vs CSR</h3>
<p>什么是服务端渲染？</p>
<p>废话不多说，直接起一个express服务器。</p>
<pre><code class="language-javascript">var express = require('express')
var app = express()

app.get('/', (req, res) =&gt; {
 res.send(
 `
   &lt;html&gt;
     &lt;head&gt;
       &lt;title&gt;hello&lt;/title&gt;
     &lt;/head&gt;
     &lt;body&gt;
       &lt;h1&gt;hello&lt;/h1&gt;
       &lt;p&gt;world&lt;/p&gt;
     &lt;/body&gt;
   &lt;/html&gt;
 `
 )
})

app.listen(3001, () =&gt; {
 console.log('listen:3001')
})
</code></pre>
<p>启动之后打开localhost:3001可以看到页面显示了hello world。而且打开网页源代码如下：<br>
<img src="https://Zu3zz.github.io/post-images/1565794815666.jpg" alt=""><br>
也能够完成显示。<br>
这就是服务端渲染。其实非常好理解，就是服务器返回一堆html字符串，然后让浏览器显示。<br>
与服务端渲染相对的是客户端渲染(Client Side Render)。那什么是客户端渲染？<br>
现在创建一个新的React项目，用脚手架生成项目，然后run起来。<br>
这里你可以看到React脚手架自动生成的首页。</p>
<p><img src="https://Zu3zz.github.io/post-images/1565794890546.jpg" alt=""><br>
然而打开网页源代码,我们会发现网页并没有任何DOM结构<br>
<img src="https://Zu3zz.github.io/post-images/1565794896346.jpg" alt=""><br>
body中除了兼容处理的noscript标签之外，只有一个id为root的标签。那首页的内容是从哪来的呢？很明显，是下面的script中拉取的JS代码控制的。<br>
因此，CSR和SSR最大的区别在于前者的页面渲染是JS负责进行的，而后者是服务器端直接返回HTML让浏览器直接渲染。<br>
为什么要使用服务端渲染呢？<br>
<img src="https://Zu3zz.github.io/post-images/1565795001030.jpeg" alt=""><br>
传统CSR的弊端：</p>
<ol>
<li>由于页面显示过程要进行JS文件拉取和React代码执行，首屏加载时间会比较慢。</li>
<li>对于SEO(Search Engine Optimazition,即搜索引擎优化)，完全无能为力，因为搜索引擎爬虫只认识html结构的内容，而不能识别JS代码内容。</li>
</ol>
<p>SSR的出现，就是为了解决这些传统CSR的弊端。</p>
<h2 id="二-实现react组件的服务端渲染">二、实现React组件的服务端渲染</h2>
<p>刚刚起的express服务返回的只是一个普通的html字符串，但我们讨论的是如何进行React的服务端渲染，那么怎么做呢？ 首先创建containers文件夹，新建一个Home.js的文件，写一个简单的React组件:</p>
<pre><code class="language-javascript">// containers/Home.js
import React from 'react';
const Home = () =&gt; {
  return (
    &lt;div&gt;
      &lt;div&gt;This is zu3zz&lt;/div&gt;
    &lt;/div&gt;
  )
}
export default Home
</code></pre>
<p>现在的任务就是将它转换为html代码返回给浏览器。<br>
总所周知，JSX中的标签其实是基于虚拟DOM的，最终要通过一定的方法将其转换为真实DOM。虚拟DOM也就是JS对象，可以看出整个服务端的渲染流程就是通过虚拟DOM的编译来完成的，因此虚拟DOM巨大的表达力也可见一斑了。<br>
而react-dom这个库中刚好实现了编译虚拟DOM的方法。做法如下:</p>
<pre><code class="language-javascript">// server/index.js
import express from 'express';
import { renderToString } from 'react-dom/server';
import Home from './containers/Home';

const app = express();
const content = renderToString(&lt;Home /&gt;);
app.get('/', function (req, res) {
   res.send(
   `
    &lt;html&gt;
      &lt;head&gt;
        &lt;title&gt;ssr&lt;/title&gt;
      &lt;/head&gt;
      &lt;body&gt;
        &lt;div id=&quot;root&quot;&gt;${content}&lt;/div&gt;
      &lt;/body&gt;
    &lt;/html&gt;
   `
   );
})
app.listen(3001, () =&gt; {
  console.log('listen:3001')
})
</code></pre>
<p>启动express服务，再浏览器上打开对应端口，页面显示出&quot;this is sanyuan&quot;。<br>
到此，就初步实现了一个React组件是服务端渲染。<br>
当然，这只是一个非常简陋的SSR，事实上对于复杂的项目而言是无能为力的，在之后会一步步完善，打造出一个功能完整的React的SSR框架。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[用优雅的代码武装我们的koa2项目]]></title>
        <id>https://Zu3zz.github.io/post/koa-tricks</id>
        <link href="https://Zu3zz.github.io/post/koa-tricks">
        </link>
        <updated>2019-08-10T08:03:41.000Z</updated>
        <summary type="html"><![CDATA[<p>👏 众所周知，koa2是基于nodejs的一款非常轻量级的服务端框架，其简单易上手的特性更是大大节省了前端人员开发服务端api的成本。<br>
💻 尽管许多功能能够实现，但是作为一个有素养的开发人员，代码的层次性、后期可维护性都是需要考虑周到的......</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏 众所周知，koa2是基于nodejs的一款非常轻量级的服务端框架，其简单易上手的特性更是大大节省了前端人员开发服务端api的成本。<br>
💻 尽管许多功能能够实现，但是作为一个有素养的开发人员，代码的层次性、后期可维护性都是需要考虑周到的......</p>
<!-- more -->
<p>实话说，按照koa官方文档来照葫芦画瓢，我们的代码是写不漂亮的。</p>
<p>这里需要我们在编码之前有一个非常清晰的认识：我们的代码如何组织？如何分层？如何复用？</p>
<p>在经历一系列的思考斟酌以及一些项目的实践之后，我总结了一些关于koa的开发技巧，能够大幅度的提高项目的代码质量，再也不用让同伴笑话代码写的烂啦！</p>
<h2 id="一路由的自动加载">一.路由的自动加载</h2>
<p>之前我们的路由总是手动注册的？大概是这样的：</p>
<pre><code class="language-javascript">//app.js
const Koa = require('koa');
const app = new Koa(); 

const user = require('./app/api/user');
const store = require('./app/api/store');

app.use(user.routes());
app.use(classic.routes());
</code></pre>
<p>对于写过koa项目的人来说，这段代码是不是相当熟悉呢？其实现在只有两个路由文件还好，但实际上这样的文件数量庞大到一定的程度，再像这样引入再use方式未免会显得繁琐拖沓。那有没有办法让这些文件自动被引入、自动被use呢？</p>
<p>有的。现在让我们来安装一个非常好用的包:<br>
<code>yarn add require-directory</code><br>
现在只需要这么做：</p>
<pre><code class="language-javascript">//...
const Router = require('koa-router'); 
const requireDirectory = require('require-directory');
//module为固定参数，'./api'为路由文件所在的路径(支持嵌套目录下的文件)，第三个参数中的visit为回调函数
const modules = requireDirectory(module, './app/api', {
    visit: whenLoadModule
});
function whenLoadModule(obj) {
    if(obj instanceof Router) {
        app.use(obj.routes());
    }
}
</code></pre>
<p>由此可见，好的代码是可以提升效率的，这样的自动加载路由省去了很多注册配置的功夫，是不是非常酷炫？</p>
<h2 id="二用管理器将入口文件内容抽离">二.用管理器将入口文件内容抽离</h2>
<p>相信很多人都这样做：路由注册代码写在了入口文件app.js中，以后进行相应中间件的导入也是写在这个文件。但是对于入口文件来说，我们是不希望让它变得十分臃肿的，因此我们可以适当地将一些操作抽离出来。</p>
<p>在根目录下建一个文件夹core，以后一些公共的代码都存放在这里。</p>
<pre><code class="language-javascript">//core/init.js
const requireDirectory = require('require-directory');
const Router = require('koa-router'); 

class InitManager {
    static initCore(app) {
        //把app.js中的koa实例传进来
        InitManager.app = app;
        InitManager.initLoadRouters();
    }
    static initLoadRouters() {
        //注意这里的路径是依赖于当前文件所在位置的
        //最好写成绝对路径
        const apiDirectory = `${process.cwd()}/app/api`
        const modules = requireDirectory(module, apiDirectory, {
            visit: whenLoadModule
        });
        function whenLoadModule(obj) {
            if(obj instanceof Router) {
                InitManager.app.use(obj.routes())
            }
        }
    }
}

module.exports = InitManager;
</code></pre>
<p>现在在app.js中</p>
<pre><code class="language-javascript">const Koa = require('koa');
const app = new Koa();

const InitManager = require('./core/init');
InitManager.initCore(app);
</code></pre>
<p>可以说已经精简很多了，而且功能的实现照样没有问题。</p>
<h2 id="三开发环境和生产环境的区分">三.开发环境和生产环境的区分</h2>
<p>有时候，在两种不同的环境下，我们需要做不同的处理，这时候就需要我们提前在全局中注入相应的参数。</p>
<p>首先在项目根目录中，创建config文件夹：</p>
<pre><code class="language-javascript">//config/config.js
module.exports = {
  environment: 'dev'
}
//core/init.js的initManager类中增加如下内容
static loadConfig() {
    const configPath = process.cwd() + '/config/config.js';
    const config = require(configPath);
    global.config = config;
}
</code></pre>
<p>现在通过全局的global变量中就可以取到当前的环境啦.</p>
<h2 id="四全局异常处理中间件">四.全局异常处理中间件</h2>
<p><strong>1.异步异常处理的坑</strong><br>
在服务端api编写的过程中，异常处理是非常重要的一环，因为不可能每个函数返回的结果都是我们想要的。无论是语法的错误，还是业务逻辑上的错误，都需要让异常抛出，让问题以最直观的方式暴露，而不是直接忽略。关于编码风格，《代码大全》里面也强调过，在一个函数遇到异常时，最好的方式不是直接return false/null，而是让异常直接抛出。</p>
<p>而在JS中，很多时候我们都在写异步代码，例如定时器，Promise等等，这就会产生一个问题，如果用try/catch的话，这样的异步代码中的错误我们是无法捕捉的。例如：</p>
<pre><code class="language-javascript">function func1() {
  try {
    func2();
  } catch (error) {
    console.log('error');
  }
}

function func2() {
  setTimeout(() =&gt; {
    throw new Error('error')
  }, 1000)
}

func1();
</code></pre>
<p>执行这些代码，你会发现过了一秒后程序直接报错，console.log('error')并没有执行，也就是func1并没有捕捉到func2的异常。这就是异步的问题所在。</p>
<p>那怎么解决这个坑呢？</p>
<p>最简便的方式是采取async-await。</p>
<pre><code class="language-javascript">async function func1() {
  try {
    await func2();
  } catch (error) {
    console.log('error');
  }
}

function func2() {
  return new Promise((resolve, reject) =&gt; {
    setTimeout(() =&gt; {
      reject()
    }, 1000)
  })
}

func1();
</code></pre>
<p>在这里的异步函数被Promise封装，然后reject触发func1中的catch，这就捕捉到了func2中的异常。庆幸的是，像func2这样的异步代码，现在常用的库(如axios、sequelize)已经为我们封装好了Promise对象，不用我们自己去封装了，直接去通过async-await的方式去try/catch就行了。</p>
<p>忠告: 通过这种方式，只要是异步代码，执行之前必须要加await，不加会报Unhandled promise rejection的错误。血的教训!</p>
<p><strong>2.设计异常处理中间件</strong></p>
<pre><code class="language-javascript">//middlewares/exception.js
//这里的工作是捕获异常生成返回的接口
const catchError = async (ctx, next) =&gt; {
  try {
    await next();
  } catch (error) {
    if(error.errorCode) {
      ctx.body = {
        msg: error.msg,
        error_code: error.errorCode,
        request: `${ctx.method} ${ctx.path}`
      };
    } else {
      //对于未知的异常，采用特别处理
      ctx.body = {
        msg: 'we made a mistake',
      };
    }
  }
}
module.exports = catchError;
</code></pre>
<p>到入口文件使用这个中间件。</p>
<pre><code class="language-javascript">//app.js
const catchError = require('./middlewares/exception');
app.use(catchError)
</code></pre>
<p>接着我们来以HttpException为例生成特定类型的异常。</p>
<pre><code class="language-javascript">//core/http-exception.js
class HttpException extends Error {
  //msg为异常信息，errorCode为错误码(开发人员内部约定),code为HTTP状态码
  constructor(msg='服务器异常', errorCode=10000, code=400) {
    super()
    this.errorCode = errorCode
    this.code = code
    this.msg = msg
  }
}

module.exports = {
  HttpException
}
//app/api/user.js
const Router = require('koa-router')
const router = new Router()
const { HttpException } = require('../../core/http-exception')

router.post('/user', (ctx, next) =&gt; {
    if(true){
        const error = new HttpException('网络请求错误', 10001, 400)
        throw error
  }
})
</code></pre>
<p>返回的接口这样:</p>
<pre><code class="language-json">{
	&quot;msg&quot;: &quot;网络请求错误&quot;,
	&quot;error_code&quot;:10001,
	&quot;request&quot;: &quot;POST /user&quot;
}
</code></pre>
<p>这样就抛出了一个特定类型的错误。但是在业务中错误的类型是非常复杂的，现在我就把我编写的一些Exception类分享一下，供大家来参考:</p>
<pre><code class="language-javascript">// http-exception.js
class HttpException extends Error {
  constructor(msg = '服务器异常', errorCode=10000, code=400) {
    super()
    this.error_code = errorCode
    this.code = code
    this.msg = msg
  }
}

class ParameterException extends HttpException{
  constructor(msg, errorCode){
    super()
    this.code = 400
    this.msg = msg || '参数错误'
    this.errorCode = errorCode || 10000
  }
}

class NotFound extends HttpException{
  constructor(msg, errorCode) {
    super();
    this.msg = msg || '资源未找到';
    this.errorCode = errorCode || 10001;
    this.code = 404;
  }
}

class AuthFailed extends HttpException{
  constructor(msg, errorCode) {
    super();
    this.msg = msg || '授权失败';
    this.errorCode = errorCode || 10002;
    this.code = 404;
  }
}

class Forbidden extends HttpException{
  constructor(msg, errorCode) {
    super();
    this.msg = msg || '禁止访问';
    this.errorCode = errorCode || 10003;
    this.code = 404;
  }
}

module.exports = {
  HttpException,
  ParameterException,
  Success,
  NotFound,
  AuthFailed,
  Forbidden
}
</code></pre>
<p>对于这种经常需要调用的错误处理的代码，有必要将它放到全局，不用每次都导入。</p>
<p>现在的init.js中是这样的：</p>
<pre><code class="language-javascript">// init.js
const requireDirectory = require('require-directory');
const Router = require('koa-router');

class InitManager {
  static initCore(app) {
    //入口方法
    InitManager.app = app;
    InitManager.initLoadRouters();
    InitManager.loadConfig();
    InitManager.loadHttpException();//加入全局的Exception
  }
  static initLoadRouters() {
    // path config
    const apiDirectory = `${process.cwd()}/app/api/v1`;
    requireDirectory(module, apiDirectory, {
      visit: whenLoadModule
    });

    function whenLoadModule(obj) {
      if (obj instanceof Router) {
        InitManager.app.use(obj.routes());
      }
    }
  }
  static loadConfig(path = '') {
    const configPath = path || process.cwd() + '/config/config.js';
    const config = require(configPath);
    global.config = config;
  }
  static loadHttpException() {
    const errors = require('./http-exception');
    global.errs = errors;
  }
}

module.exports = InitManager;
</code></pre>
<h2 id="五使用jwt完成认证授权">五.使用JWT完成认证授权</h2>
<p>JWT(即Json Web Token)目前最流行的跨域身份验证解决方案之一。它的工作流程是这样的：</p>
<p>1.前端向后端传递用户名和密码</p>
<p>2.用户名和密码在后端核实成功后，返回前端一个token(或存在cookie中)</p>
<p>3.前端拿到token并进行保存</p>
<p>4.前端访问后端接口时先进行token认证，认证通过才能访问接口。</p>
<p>那么在koa中我们需要做哪些事情？</p>
<p>在生成token阶段：首先是验证账户，然后生成token令牌，传给前端。</p>
<p>在认证token阶段: 完成认证中间件的编写，对前端的访问做一层拦截，token认证过后才能访问后面的接口。</p>
<p><strong>1.生成token</strong><br>
先安装两个包:</p>
<pre><code class="language-javascript">yarn add jsonwebtoken basic-auth
//config.js
module.exports = {
  environment: 'dev',
  database: {
    dbName: 'island',
    host: 'localhost',
    port: 3306,
    user: 'root',
    password: 'fjfj'
  },
  security: {
    secretKey: 'lajsdflsdjfljsdljfls',//用来生成token的key值
    expiresIn: 60 * 60//过期时间
  }
}

//utils.js 
//生成token令牌函数，uid为用户id，scope为权限等级(类型为数字，内部约定)
const generateToken = function(uid, scope){
    const { secretKey, expiresIn } = global.config.security
    //第一个参数为用户信息的js对象，第二个为用来生成token的key值，第三个为配置项
    const token = jwt.sign({
        uid,
        scope
    },secretKey,{
        expiresIn
    })
    return token
}
</code></pre>
<p><strong>2.Auth中间件实现拦截</strong></p>
<pre><code class="language-javascript">//前端传token方式
//在请求头中加上Authorization:`Basic ${base64(token+&quot;:&quot;)}`即可
//其中base64为第三方库js-base64导出的一个方法

//middlewares/auth.js
const basicAuth = require('basic-auth');
const jwt = require('jsonwebtoken');

class Auth {
  constructor(level) {
    Auth.USER = 8;
    Auth.ADMIN = 16;
    this.level = level || 1;
  }
  //注意这里的m是一个属性
  get m() {
    return async (ctx, next) =&gt; {
      const userToken = basicAuth(ctx.req);
      let errMsg = 'token不合法';

      if(!userToken || !userToken.name) {
        throw new global.errs.Forbidden();
      }
      try {
        //将前端传过来的token值进行认证，如果成功会返回一个decode对象，包含uid和scope
        var decode = jwt.verify(userToken.name, global.config.security.secretKey);
      } catch (error) {
        // token不合法
        // 或token过期
        // 抛异常
        errMsg = '//根据情况定义'
        throw new global.errs.Forbidden(errMsg);
      }
      //将uid和scope挂载ctx中
      ctx.auth = {
        uid: decode.uid,
        scope: decode.scope
      };
      //现在走到这里token认证通过
      await next();
    }
  }
}
module.exports = Auth;
</code></pre>
<p>在路由相应文件中编写如下:</p>
<pre><code class="language-javascript">//中间件先行，如果中间件中认证未通过，则不会走到路由处理逻辑这里来
router.post('/xxx', new Auth().m , async (ctx, next) =&gt; {
    //......
})
</code></pre>
<h2 id="六require路径别名">六.require路径别名</h2>
<p>在开发的过程，当项目的目录越来越复杂的时候，包的引用路径也变得越来越麻烦。曾经就出现过这样的导入路径:</p>
<pre><code class="language-javascript">const Favor = require('../../../models/favor');
</code></pre>
<p>甚至还有比这个更加冗长的导入方式，作为一个有代码洁癖的程序员，实在让人看的非常不爽。其实通过绝对路径process.cwd()的方式也是可以解决这样一个问题的，但是当目录深到一定程度的时候，导入的代码也非常繁冗。那有没有更好的解决方式呢？</p>
<p>使用module-alias将路径别名就可以。</p>
<pre><code class="language-javascript">yarn add module-alias
//package.json添加如下内容
  &quot;_moduleAliases&quot;: {
    &quot;@models&quot;: &quot;app/models&quot;
  },
</code></pre>
<p>然后在app.js引入这个库：</p>
<pre><code class="language-javascript">//引入即可
require('module-alias/register');
</code></pre>
<p>现在引入代码就变成这样了:</p>
<pre><code class="language-javascript">const Favor = require('@models/favor');
</code></pre>
<p>简洁清晰了许多，也更容易让人维护。</p>
<h2 id="七利用sequelize的事务解决数据不一致问题">七.利用sequelize的事务解决数据不一致问题</h2>
<p>当一个业务要进行多项数据库的操作时，拿点赞功能为例，首先你得在点赞记录的表中增加记录，然后你要将对应对象的点赞数加1，这两个操作是必须要一起完成的，如果有一个操作成功，另一个操作出现了问题，那就会导致数据不一致，这是一个非常严重的安全问题。</p>
<p>我们希望如果出现了任何问题，直接回滚到未操作之前的状态。这个时候建议用数据库事务的操作。利用sequelize的transaction是可以完成的，把业务部分的代码贴一下:</p>
<pre><code class="language-javascript">async like(art_id, uid) {
    //查找是否有重复的
    const favor = await Favor.findOne({
      where: { art_id, uid }
      }
    );
    //有重复则抛异常
    if (favor) {
      throw new global.errs.LikeError('你已经点过赞了');
    }
    //db为sequelize的实例
    //下面是事务的操作
    return db.transaction(async t =&gt; {
      //1.创建点赞记录
      await Favor.create({ art_id, uid }, { transaction: t });
      //2.增加点赞数
      const art = await Art.getData(art_id, type);//拿到被点赞的对象
      await art.increment('fav_nums', { by: 1, transaction: t });//加1操作
    });
  }
</code></pre>
<p>sequelize中的transaction大概就是这样做的，官方文档是promise的方式，看起来实在太不美观，改成async/await方式会好很多，但是千万不要忘了写await。</p>
<p>关于koa2的代码优化，就先分享到这里，未完待续，后续会不断补充。欢迎点赞、留言!</p>
]]></content>
    </entry>
</feed>